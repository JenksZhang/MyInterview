# 操作系统面试知识点

> 按照重要程度排序，优先掌握⭐⭐⭐⭐⭐必考题

---

## 进程与线程

## 📌 进程与线程的区别（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **资源分配** | **调度单位** | **地址空间** | **开销** | **通信方式** | **健壮性** | **上下文切换**

### ✅ 核心区别对比

| 特性 | 进程(Process) | 线程(Thread) |
|------|--------------|-------------|
| **定义** | 资源分配的基本单位 | CPU调度的基本单位 |
| **地址空间** | 独立地址空间 | 共享进程地址空间 |
| **资源拥有** | 拥有独立资源 | 共享进程资源 |
| **开销** | 创建/切换开销大 | 创建/切换开销小 |
| **通信** | IPC(管道/消息队列/共享内存) | 直接读写共享变量 |
| **健壮性** | 进程间独立，一个崩溃不影响其他 | 一个线程崩溃可能导致整个进程崩溃 |
| **并发性** | 可在多核上真正并行 | 可在多核上真正并行 |

### 💡 内存布局对比（⭐⭐⭐⭐⭐ 必问）

**进程的内存布局：**
```
进程A                    进程B
┌──────────────┐        ┌──────────────┐
│  内核空间    │ ←─共享→ │  内核空间    │
├──────────────┤        ├──────────────┤
│   栈(Stack)  │        │   栈(Stack)  │
│      ↓       │        │      ↓       │
│  (未使用空间) │        │  (未使用空间) │
│      ↑       │        │      ↑       │
│   堆(Heap)   │        │   堆(Heap)   │
├──────────────┤        ├──────────────┤
│   BSS段      │        │   BSS段      │
│   Data段     │        │   Data段     │
│   Text段     │        │   Text段     │
└──────────────┘        └──────────────┘
  独立地址空间             独立地址空间
```

**线程的内存布局：**
```
进程内的多线程
┌───────────────────────────────┐
│        内核空间               │
├───────────────────────────────┤
│  线程1栈  │ 线程2栈  │ 线程3栈  │ ← 各自独立
├───────────────────────────────┤
│                               │
│      堆 (共享)                │
│                               │
├───────────────────────────────┤
│    BSS段 (共享)               │
│    Data段 (共享)              │
│    Text段 (共享)              │
└───────────────────────────────┘
  同一地址空间
```

### 💻 上下文切换开销对比

**进程上下文切换：**
```cpp
// 进程切换需要保存和恢复的内容
struct ProcessContext {
    // 1. CPU寄存器状态
    Register registers[32];     // 通用寄存器
    Register PC;                // 程序计数器
    Register SP;                // 栈指针

    // 2. 内存管理信息
    PageTable* page_table;      // 🔑 页表切换(最大开销)

    // 3. 文件描述符表
    FileDescriptor* fd_table;

    // 4. 信号处理
    SignalHandler* signals;

    // 总开销：约1000-1500个CPU周期
};

// 🔑 关键：切换页表会导致TLB(Translation Lookaside Buffer)失效
// 需要重新建立虚拟地址到物理地址的映射
```

**线程上下文切换：**
```cpp
// 线程切换只需保存
struct ThreadContext {
    // 1. CPU寄存器状态
    Register registers[32];
    Register PC;
    Register SP;

    // 🔑 不需要切换：
    // - 页表(共享进程页表)
    // - 文件描述符(共享)
    // - 信号处理(共享)

    // 总开销：约100-200个CPU周期
};

// ✅ 线程切换比进程切换快5-10倍
```

**性能测试示例：**
```cpp
// 测试进程创建开销
auto start = chrono::high_resolution_clock::now();
for (int i = 0; i < 10000; ++i) {
    pid_t pid = fork();
    if (pid == 0) {
        exit(0);  // 子进程立即退出
    }
    waitpid(pid, nullptr, 0);
}
auto end = chrono::high_resolution_clock::now();
// 典型结果: 约5000ms

// 测试线程创建开销
start = chrono::high_resolution_clock::now();
for (int i = 0; i < 10000; ++i) {
    thread t([]{ });
    t.join();
}
end = chrono::high_resolution_clock::now();
// 典型结果: 约500ms

// 🔑 线程创建比进程创建快约10倍
```

### 🔥 面试追问点

#### 1️⃣ 为什么线程称为"轻量级进程"？（⭐⭐⭐⭐⭐ 必问）

```
轻量级的原因：
1. 创建开销小
   - 进程：需要分配独立地址空间、页表、文件描述符表等
   - 线程：只需分配栈空间和寄存器

2. 切换开销小
   - 进程：需要切换页表(cr3寄存器)，导致TLB失效
   - 线程：不需要切换页表，只需切换寄存器

3. 通信开销小
   - 进程：需要IPC机制(管道、消息队列、共享内存)
   - 线程：直接读写共享变量(需同步机制)

4. 资源占用小
   - 进程：MB级别(独立地址空间)
   - 线程：KB级别(只有栈空间)
```

#### 2️⃣ 多线程一定比多进程快吗？（⭐⭐⭐⭐⭐ 高频）

```cpp
// ❌ 不一定！取决于场景

// 场景1：CPU密集型 + 计算独立
// ✅ 多线程更快（共享缓存，切换开销小）
void cpuIntensive() {
    // 矩阵计算、图像处理等
    // 线程间数据独立，缓存命中率高
}

// 场景2：需要高隔离性和安全性
// ✅ 多进程更好（Chrome浏览器的多进程架构）
// 原因：一个页面崩溃不影响其他页面

// 场景3：大量锁竞争
// ❌ 多线程可能更慢
mutex mtx;
void withContention() {
    lock_guard<mutex> lock(mtx);  // 大量线程竞争锁
    // 关键区很小
}
// 锁竞争导致线程频繁阻塞，性能不如多进程

// 场景4：I/O密集型
// ✅ 多线程更快（共享文件描述符，切换开销小）
void ioIntensive() {
    read(fd, buf, size);  // 线程阻塞在I/O
    // 其他线程继续执行
}
```

#### 3️⃣ 线程共享哪些资源？不共享哪些？（⭐⭐⭐⭐⭐ 必问）

**共享资源：**
```cpp
// ✅ 同一进程的线程共享
1. 代码段(Text)        // 所有线程执行相同代码
2. 数据段(Data)        // 全局变量、静态变量
3. 堆(Heap)           // new/malloc分配的内存
4. 文件描述符         // 打开的文件
5. 信号处理器         // 信号处理函数
6. 当前工作目录       // cwd
7. 用户ID和组ID       // uid, gid

// 示例：
int g_shared = 0;  // Data段，所有线程共享

void thread_func() {
    g_shared++;  // ⚠️ 需要同步

    int* p = new int(10);  // 堆，所有线程可访问
    // ⚠️ 任何线程都可以delete p
}
```

**独占资源：**
```cpp
// ❌ 线程独有，不共享
1. 栈空间(Stack)        // 局部变量、函数参数
2. 寄存器(Register)     // PC、SP等
3. 线程ID(TID)
4. 信号掩码(Signal Mask)
5. errno变量

// 示例：
void thread_func() {
    int local = 10;  // 栈，线程独有

    // 每个线程有独立的栈帧
    func1();
    func2();
}

// 🔑 这就是为什么递归函数在多线程中安全
// 每个线程有自己的栈，递归调用不会互相影响
```

#### 4️⃣ 如何选择多进程还是多线程？（⭐⭐⭐⭐⭐ 高频）

```
选择多进程：
✅ 1. 需要高隔离性和安全性
   - 浏览器(Chrome): 每个标签页一个进程
   - Web服务器(Nginx): worker进程隔离

✅ 2. 不需要频繁通信
   - 离线任务处理
   - 独立的计算任务

✅ 3. 需要利用多机分布式
   - 分布式计算框架

选择多线程：
✅ 1. 需要频繁通信和数据共享
   - 图形界面程序: UI线程 + 工作线程
   - 游戏引擎: 渲染线程 + 逻辑线程

✅ 2. 资源占用敏感
   - 移动端应用
   - 嵌入式系统

✅ 3. 需要快速响应
   - 实时系统
   - 高频交易系统
```

### 🎓 面试回答模板

```
【标准回答】（30秒版本）
进程和线程的主要区别：

1. 资源分配
   - 进程是资源分配的基本单位，拥有独立地址空间
   - 线程是CPU调度的基本单位，共享进程资源

2. 开销
   - 进程创建和切换开销大(需要切换页表)
   - 线程创建和切换开销小(只需切换寄存器)
   - 线程切换比进程切换快5-10倍

3. 通信
   - 进程间通信需要IPC机制(管道、消息队列、共享内存等)
   - 线程间直接读写共享变量(需要同步机制)

4. 健壮性
   - 进程独立，一个崩溃不影响其他
   - 线程共享地址空间，一个崩溃整个进程崩溃

【追问-为什么进程切换慢】
进程切换需要：
1. 切换页表(修改cr3寄存器)
2. 导致TLB(快表)失效
3. 需要重新建立虚拟地址到物理地址的映射
4. 还要切换文件描述符表、信号处理等

线程切换只需要切换寄存器，不涉及内存管理。

【追问-如何选择】
多进程：需要隔离性、安全性、分布式
多线程：需要频繁通信、资源敏感、快速响应
```

### ⚠️ 常见误区

❌ **错误1**：线程一定比进程快
✅ **正确**：取决于场景，大量锁竞争时多线程可能更慢

❌ **错误2**：线程没有自己的资源
✅ **正确**：线程有独立的栈空间、寄存器、线程ID

❌ **错误3**：进程间完全无法共享内存
✅ **正确**：可以通过共享内存IPC机制共享

### 🌟 加分点

- 提到具体的切换开销数值(进程1000-1500周期，线程100-200周期)
- 知道TLB失效对性能的影响
- 了解Chrome多进程架构的设计原因
- 提到协程(用户态线程)的概念

---

## 📌 进程间通信(IPC)（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **管道(Pipe)** | **消息队列** | **共享内存** | **信号量** | **Socket** | **信号(Signal)** | **最快的IPC**

### ✅ 七种IPC方式对比

| IPC方式 | 速度 | 容量 | 是否需要同步 | 应用场景 |
|---------|------|------|-------------|---------|
| **管道(Pipe)** | 中等 | 64KB | 否 | 父子进程简单通信 |
| **命名管道(FIFO)** | 中等 | 64KB | 否 | 无关进程通信 |
| **消息队列** | 中等 | 无限制 | 否 | 结构化消息传递 |
| **共享内存** | ⭐最快 | 无限制 | 是 | 大量数据交换 |
| **信号量** | 中等 | - | 是(本身就是同步机制) | 进程同步 |
| **Socket** | 慢 | 无限制 | 否 | 网络/本机通信 |
| **信号(Signal)** | 快 | 极小 | 否 | 异步通知 |

### 💡 各IPC方式详解

#### 1️⃣ 管道(Pipe)（⭐⭐⭐⭐⭐ 必考）

**特点：**
```cpp
// 管道是半双工的：数据单向流动
// 只能用于父子进程或兄弟进程

int main() {
    int pipefd[2];  // pipefd[0]:读端, pipefd[1]:写端
    pipe(pipefd);

    pid_t pid = fork();

    if (pid == 0) {  // 子进程
        close(pipefd[1]);  // 关闭写端

        char buf[100];
        read(pipefd[0], buf, sizeof(buf));  // 从管道读
        printf("Child received: %s\n", buf);

        close(pipefd[0]);
    } else {  // 父进程
        close(pipefd[0]);  // 关闭读端

        write(pipefd[1], "Hello", 6);  // 写入管道

        close(pipefd[1]);
        wait(nullptr);
    }
}

// 🔑 管道的本质：
// 内核维护的循环缓冲区(默认64KB)
```

**管道的底层实现：**
```
内核中的管道缓冲区：
┌──────────────────────────────────┐
│  循环缓冲区 (64KB)                │
│  ┌─────────────────────────┐     │
│  │ 数据...                 │     │
│  └─────────────────────────┘     │
│   ↑                      ↑       │
│  读指针                写指针     │
└──────────────────────────────────┘

写满时：write()阻塞
读空时：read()阻塞
```

**命名管道(FIFO)：**
```cpp
// 可用于无关进程通信
// 1. 创建FIFO
mkfifo("/tmp/myfifo", 0666);

// 进程A：写入
int fd = open("/tmp/myfifo", O_WRONLY);
write(fd, "data", 5);
close(fd);

// 进程B：读取
int fd = open("/tmp/myfifo", O_RDONLY);
read(fd, buf, sizeof(buf));
close(fd);
```

#### 2️⃣ 消息队列(Message Queue)（⭐⭐⭐⭐）

**特点：**
```cpp
// 消息队列：消息的链表，存放在内核中
// 优点：可以传递结构化数据

struct msgbuf {
    long mtype;      // 消息类型
    char mtext[100]; // 消息数据
};

// 创建消息队列
key_t key = ftok("/tmp", 'A');
int msgid = msgget(key, IPC_CREAT | 0666);

// 发送消息
struct msgbuf msg;
msg.mtype = 1;
strcpy(msg.mtext, "Hello");
msgsnd(msgid, &msg, sizeof(msg.mtext), 0);

// 接收消息
struct msgbuf rcv;
msgrcv(msgid, &rcv, sizeof(rcv.mtext), 1, 0);  // 接收类型1的消息

// 删除消息队列
msgctl(msgid, IPC_RMID, nullptr);

// 🔑 优点：
// 1. 可以按类型选择性接收
// 2. 不需要同步机制
// 3. 可以传递结构化数据

// ❌ 缺点：
// 1. 有大小限制
// 2. 需要数据拷贝(用户空间 ↔ 内核空间)
```

#### 3️⃣ 共享内存(Shared Memory)（⭐⭐⭐⭐⭐ 必考、最快）

**特点：**
```cpp
// ⭐ 最快的IPC方式
// 原理：多个进程直接访问同一块物理内存

// 创建共享内存
key_t key = ftok("/tmp", 'B');
int shmid = shmget(key, 4096, IPC_CREAT | 0666);

// 映射到进程地址空间
char* shmaddr = (char*)shmat(shmid, nullptr, 0);

// 直接读写
strcpy(shmaddr, "Shared data");
printf("%s\n", shmaddr);

// 解除映射
shmdt(shmaddr);

// 删除共享内存
shmctl(shmid, IPC_RMID, nullptr);

// 🔑 为什么最快？
// 避免了数据拷贝：
// 管道/消息队列：用户空间 → 内核 → 用户空间 (2次拷贝)
// 共享内存：用户空间 → 用户空间 (0次拷贝)
```

**共享内存的内存布局：**
```
进程A地址空间         进程B地址空间
┌────────────┐        ┌────────────┐
│  内核空间  │        │  内核空间  │
├────────────┤        ├────────────┤
│    栈      │        │    栈      │
├────────────┤        ├────────────┤
│   共享内存  │ ←映射→ │   共享内存  │
│   (同一块   │        │   物理内存) │
├────────────┤        ├────────────┤
│    堆      │        │    堆      │
└────────────┘        └────────────┘

🔑 两个进程的虚拟地址映射到同一块物理内存
```

**⚠️ 共享内存需要同步机制：**
```cpp
// ❌ 问题：多个进程同时写
进程A: shmaddr[0] = 'A';
进程B: shmaddr[0] = 'B';  // 竞争条件

// ✅ 解决：配合信号量使用
sem_t* sem = sem_open("/mysem", O_CREAT, 0666, 1);

// 进程A
sem_wait(sem);  // P操作
strcpy(shmaddr, "Data from A");
sem_post(sem);  // V操作

// 进程B
sem_wait(sem);
strcpy(shmaddr, "Data from B");
sem_post(sem);
```

#### 4️⃣ 信号量(Semaphore)（⭐⭐⭐⭐⭐ 必考）

**特点：**
```cpp
// 信号量本质：内核维护的整数计数器
// 主要用于进程同步和互斥

// POSIX信号量
sem_t* sem = sem_open("/mysem", O_CREAT, 0666, 1);
// 第4个参数：初始值，1表示互斥量

// P操作(wait)：计数-1，为0则阻塞
sem_wait(sem);
// 临界区
sem_post(sem);  // V操作(signal)：计数+1

// System V信号量(更强大，支持信号量集)
key_t key = ftok("/tmp", 'C');
int semid = semget(key, 1, IPC_CREAT | 0666);

// 初始化
semctl(semid, 0, SETVAL, 1);

// P操作
struct sembuf p_op = {0, -1, SEM_UNDO};
semop(semid, &p_op, 1);

// 临界区

// V操作
struct sembuf v_op = {0, 1, SEM_UNDO};
semop(semid, &v_op, 1);
```

**信号量vs互斥锁：**
```cpp
// 互斥锁：
// - 谁加锁谁解锁
// - 只能是0或1(二值)

// 信号量：
// - 任何进程都可以释放
// - 可以>1(计数信号量)

// 示例：生产者-消费者
sem_t* empty = sem_open("/empty", O_CREAT, 0666, N);  // N个空槽
sem_t* full = sem_open("/full", O_CREAT, 0666, 0);   // 0个满槽

// 生产者
sem_wait(empty);  // 等待空槽
// 生产数据
sem_post(full);   // 增加满槽

// 消费者
sem_wait(full);   // 等待满槽
// 消费数据
sem_post(empty);  // 增加空槽
```

#### 5️⃣ Socket（⭐⭐⭐⭐）

```cpp
// Socket：可用于本机或网络通信

// Unix Domain Socket(本机通信，比网络Socket快)
int sockfd = socket(AF_UNIX, SOCK_STREAM, 0);

struct sockaddr_un addr;
addr.sun_family = AF_UNIX;
strcpy(addr.sun_path, "/tmp/mysocket");

bind(sockfd, (struct sockaddr*)&addr, sizeof(addr));
listen(sockfd, 5);

// 网络Socket
int sockfd = socket(AF_INET, SOCK_STREAM, 0);
// ...

// 🔑 Socket vs 其他IPC：
// 优点：统一接口，跨机器通信
// 缺点：开销较大，速度最慢
```

#### 6️⃣ 信号(Signal)（⭐⭐⭐⭐）

```cpp
// 信号：用于通知进程发生了某事件

// 发送信号
kill(pid, SIGTERM);  // 向进程发送终止信号

// 接收信号
void signal_handler(int sig) {
    if (sig == SIGTERM) {
        // 清理资源
        exit(0);
    }
}

signal(SIGTERM, signal_handler);

// 常见信号：
// SIGKILL(9)  - 强制终止(不可捕获)
// SIGTERM(15) - 请求终止(可捕获)
// SIGCHLD     - 子进程状态改变
// SIGUSR1/2   - 用户自定义信号

// 🔑 信号的特点：
// 1. 异步通知
// 2. 传递信息量极小(只有信号类型)
// 3. 不能传递数据(只能通知事件)
```

### 🔥 面试追问点

#### 1️⃣ 哪种IPC方式最快？为什么？（⭐⭐⭐⭐⭐ 必问）

```
答案：共享内存最快

原因：
1. 零拷贝
   - 管道/消息队列：用户空间→内核→用户空间(2次拷贝)
   - 共享内存：用户空间→用户空间(0次拷贝)

2. 直接内存访问
   - 其他IPC：需要系统调用(用户态→内核态切换)
   - 共享内存：读写操作直接访问内存(无系统调用)

性能对比(传输1MB数据)：
- 共享内存: ~0.1ms
- 管道:     ~5ms   (50倍慢)
- 消息队列: ~10ms  (100倍慢)
- Socket:   ~20ms  (200倍慢)

🔑 但共享内存需要额外的同步机制(信号量)
```

#### 2️⃣ 管道和消息队列的区别？（⭐⭐⭐⭐）

```
管道：
✅ 简单，适合父子进程
✅ 半双工，数据单向流动
❌ 无格式字节流
❌ 有大小限制(64KB)
❌ 只能用于亲缘进程(匿名管道)

消息队列：
✅ 可用于无关进程
✅ 可按类型选择性接收
✅ 支持结构化数据
✅ 无固定大小限制
❌ 需要数据拷贝
❌ 更复杂

选择：
- 简单父子通信 → 管道
- 复杂消息传递 → 消息队列
```

#### 3️⃣ 共享内存为什么需要信号量？（⭐⭐⭐⭐⭐ 高频）

```cpp
// 问题：竞争条件(Race Condition)

// 场景：两个进程同时修改共享内存
// 进程A                进程B
int* count = shmaddr;   int* count = shmaddr;
(*count)++;             (*count)++;

// 汇编级别：
load  count → reg       load  count → reg
add   1     → reg       add   1     → reg
store reg   → count     store reg   → count

// 可能的执行序列：
1. A: load count(0) → reg
2. B: load count(0) → reg
3. A: add 1 → reg(1)
4. B: add 1 → reg(1)
5. A: store 1 → count
6. B: store 1 → count
// 结果：count = 1 (期望是2)

// ✅ 解决：信号量保护
sem_wait(sem);
(*count)++;
sem_post(sem);

// 🔑 共享内存提供"快速通道"
// 信号量提供"交通信号灯"
```

### 🎓 面试回答模板

```
【标准回答】
进程间通信有7种主要方式：

1. 管道(Pipe)
   - 半双工，数据单向流动
   - 只能用于父子进程
   - 适合简单通信

2. 命名管道(FIFO)
   - 可用于无关进程
   - 有名字的管道文件

3. 消息队列(Message Queue)
   - 消息的链表，存在内核中
   - 支持结构化数据
   - 可按类型接收

4. 共享内存(Shared Memory) ⭐最快
   - 直接映射同一块物理内存
   - 零拷贝，性能最高
   - 需要配合信号量同步

5. 信号量(Semaphore)
   - 用于进程同步和互斥
   - 本质是计数器

6. Socket
   - 可用于网络和本机
   - 统一接口
   - 速度最慢

7. 信号(Signal)
   - 异步通知机制
   - 传递信息量极小

【追问-哪种最快】
共享内存最快，因为：
1. 零拷贝(直接内存访问)
2. 无系统调用开销
3. 比管道快50倍，比Socket快200倍

但需要配合信号量解决同步问题。

【追问-如何选择】
- 父子进程简单通信 → 管道
- 需要结构化消息 → 消息队列
- 大量数据交换 → 共享内存+信号量
- 跨机器通信 → Socket
- 异步通知 → 信号
```

### ⚠️ 常见误区

❌ **错误1**：共享内存不需要同步
✅ **正确**：共享内存是最快的IPC，但必须配合信号量等同步机制

❌ **错误2**：管道可以双向通信
✅ **正确**：管道是半双工的，需要两个管道才能双向通信

❌ **错误3**：消息队列比共享内存快
✅ **正确**：共享内存最快，消息队列需要数据拷贝

### 🌟 加分点

- 提到共享内存零拷贝的原理
- 知道管道的默认缓冲区大小(64KB)
- 了解Unix Domain Socket比网络Socket快的原因
- 提到mmap也可以实现进程间共享内存
- 知道System V IPC和POSIX IPC的区别

---

## 📌 进程调度算法（⭐⭐⭐⭐ 高频）

### 🎯 得分关键词
> **先来先服务(FCFS)** | **最短作业优先(SJF)** | **时间片轮转(RR)** | **优先级调度** | **多级反馈队列** | **完全公平调度(CFS)**

### ✅ 五种经典调度算法

| 算法 | 特点 | 优点 | 缺点 | 适用场景 |
|------|------|------|------|---------|
| **FCFS** | 先到先服务 | 简单 | 平均等待时间长 | 批处理系统 |
| **SJF** | 最短作业优先 | 平均等待时间最短 | 饥饿、需预知时间 | 批处理 |
| **RR** | 时间片轮转 | 公平、响应快 | 上下文切换多 | 分时系统 |
| **优先级** | 按优先级调度 | 灵活 | 饥饿问题 | 实时系统 |
| **多级反馈** | 综合多种策略 | 自适应 | 复杂 | 通用操作系统 |

### 💡 调度算法详解

#### 1️⃣ 先来先服务(FCFS)（⭐⭐⭐⭐）

```cpp
// 最简单的调度算法：队列

进程到达顺序: P1(24ms) → P2(3ms) → P3(3ms)

执行顺序: P1 | P2 | P3
时间轴:   0  24  27  30

等待时间:
P1: 0
P2: 24
P3: 27
平均等待时间 = (0 + 24 + 27) / 3 = 17ms

// ❌ 护航效应(Convoy Effect)
// 短作业被长作业延误

// 如果P2先到达：
执行顺序: P2 | P3 | P1
时间轴:   0   3   6  30

等待时间:
P2: 0
P3: 3
P1: 6
平均等待时间 = (0 + 3 + 6) / 3 = 3ms

// 🔑 到达顺序影响巨大！
```

#### 2️⃣ 最短作业优先(SJF)（⭐⭐⭐⭐⭐ 必考）

```cpp
// 原理：总是选择执行时间最短的作业

进程: P1(6ms), P2(8ms), P3(7ms), P4(3ms)

// SJF调度顺序: P4 → P1 → P3 → P2
执行顺序: P4 | P1 | P3 | P2
时间轴:   0   3   9  16  24

等待时间:
P4: 0
P1: 3
P3: 9
P2: 16
平均等待时间 = (0 + 3 + 9 + 16) / 4 = 7ms

// ✅ SJF是最优的(平均等待时间最短)

// ❌ 问题：
// 1. 饥饿：长作业可能永远得不到执行
// 2. 需要预知执行时间(实际中无法准确知道)

// 抢占式SJF(最短剩余时间优先SRTF)
时刻0: P1到达(8ms)
时刻1: P2到达(4ms) → 抢占P1
时刻5: P2完成，P1继续(剩余7ms)
时刻5: P3到达(1ms) → 抢占P1
时刻6: P3完成，P1继续

// 🔑 每次新进程到达，比较剩余时间
```

**SJF的最优性证明：**
```
定理：SJF的平均等待时间最短

证明(交换论证)：
假设有调度S不是SJF，存在两个相邻作业i, j
其中 time[i] > time[j]，但i排在j前面

交换i和j后：
- i的等待时间增加time[j]
- j的等待时间减少time[i]
- 总等待时间减少 time[i] - time[j] > 0

因此，非SJF调度总能通过交换得到更优解
故SJF最优。
```

#### 3️⃣ 时间片轮转(RR)（⭐⭐⭐⭐⭐ 必考）

```cpp
// 每个进程分配一个时间片(quantum)
// 时间片用完，强制切换到下一个进程

进程: P1(24ms), P2(3ms), P3(3ms)
时间片: 4ms

执行过程:
0-4ms:   P1执行4ms (剩余20ms)
4-7ms:   P2执行3ms (完成)
7-10ms:  P3执行3ms (完成)
10-14ms: P1执行4ms (剩余16ms)
14-18ms: P1执行4ms (剩余12ms)
18-22ms: P1执行4ms (剩余8ms)
22-26ms: P1执行4ms (剩余4ms)
26-30ms: P1执行4ms (完成)

平均等待时间 = (6 + 4 + 7) / 3 = 5.67ms

// 🔑 时间片大小的影响：
// - 太大 → 退化为FCFS
// - 太小 → 上下文切换开销大

// 典型时间片：10-100ms
// 上下文切换：1ms

// 最优时间片：
// 上下文切换开销占比 < 1%
// quantum > 100 * switch_time
// 如switch_time=1ms，则quantum > 100ms
```

**时间片选择的权衡：**
```
时间片 = 1ms (太小)
┌─┬─┬─┬─┬─┬─┬─┬─┐
│1│切│1│切│1│切│1│切│
└─┴─┴─┴─┴─┴─┴─┴─┘
上下文切换开销: 50%

时间片 = 100ms (合适)
┌──────────┬──────────┬──────────┐
│   100ms  │  100ms   │  100ms   │
└──────────┴──────────┴──────────┘
上下文切换开销: 1%

时间片 = 无穷大 (太大)
┌──────────────────────────────────┐
│          FCFS                    │
└──────────────────────────────────┘
响应时间长
```

#### 4️⃣ 优先级调度（⭐⭐⭐⭐）

```cpp
// 每个进程分配一个优先级
// 总是调度优先级最高的进程

进程:    P1(10ms, priority=3)
        P2(1ms,  priority=1)  // 数字越小优先级越高
        P3(2ms,  priority=4)
        P4(1ms,  priority=5)
        P5(5ms,  priority=2)

// 调度顺序: P2 → P5 → P1 → P3 → P4

// ❌ 饥饿问题：
// 低优先级进程可能永远得不到执行

// ✅ 解决：优先级老化(Aging)
// 等待时间越长，优先级越高
void aging() {
    for (auto& process : waiting_queue) {
        process.priority--;  // 优先级提升
        if (process.wait_time > threshold) {
            process.priority = 0;  // 提升到最高
        }
    }
}

// 实时系统中的优先级
// 硬实时：deadline前必须完成
// 软实时：尽量在deadline前完成

// Linux的nice值：-20(最高) ~ 19(最低)
nice -n 10 ./my_program  // 降低优先级
```

#### 5️⃣ 多级反馈队列(MLFQ)（⭐⭐⭐⭐⭐ 必考、现代OS常用）

```cpp
// 综合FCFS、RR、优先级的优点

多级队列结构:
┌────────────────────────────┐
│ Q0(最高优先级) - 时间片8ms  │ → FCFS
├────────────────────────────┤
│ Q1(中优先级)  - 时间片16ms │ → RR
├────────────────────────────┤
│ Q2(低优先级)  - 时间片32ms │ → RR
└────────────────────────────┘

调度规则：
1. 新进程进入Q0
2. Q0的进程用完时间片 → 降到Q1
3. Q1的进程用完时间片 → 降到Q2
4. Q2的进程用FCFS调度

5. 只有Q0为空时，才调度Q1
6. 只有Q0和Q1都为空时，才调度Q2

// 🔑 自适应特性：
// - I/O密集型进程：频繁阻塞，留在高优先级队列
// - CPU密集型进程：用完时间片，降到低优先级队列

示例：
进程P1(I/O密集): 执行5ms → I/O → 执行5ms → I/O
  始终在Q0

进程P2(CPU密集): 执行8ms → 降到Q1 → 执行16ms → 降到Q2
  最终在Q2

// ✅ 优点：
// 1. 短进程响应快(留在高优先级)
// 2. 长进程不会饿死(最终进Q2)
// 3. I/O进程优先(交互式程序响应快)
```

**MLFQ的反馈机制：**
```
进程行为变化时自动调整：

CPU密集型转I/O密集型:
Q2 → 频繁I/O → 提升到Q0

I/O密集型转CPU密集型:
Q0 → 长时间运行 → 降到Q2

// Linux的CFS(Completely Fair Scheduler)
// 类似思想，但使用红黑树而非队列
```

#### 6️⃣ Linux CFS调度器（⭐⭐⭐⭐⭐ 加分项）

```cpp
// CFS核心思想：让每个进程获得公平的CPU时间

// 虚拟运行时间(vruntime)
vruntime = 实际运行时间 * (NICE_0_LOAD / 进程权重)

// 权重与nice值的关系
weight = 1024 / (1.25 ^ nice)

nice = 0:  weight = 1024
nice = 5:  weight = 335
nice = -5: weight = 3121

// CFS调度算法
1. 所有可运行进程组成红黑树(按vruntime排序)
2. 每次调度选择vruntime最小的进程(红黑树最左节点)
3. 进程运行后更新vruntime
4. 重新插入红黑树

// 🔑 vruntime小的进程获得更多CPU时间
// 保证所有进程的vruntime趋于相等(公平)

struct sched_entity {
    u64 vruntime;       // 虚拟运行时间
    u64 exec_start;     // 开始执行时刻
    struct rb_node run_node;  // 红黑树节点
};

// 时间复杂度: O(log n)
```

### 🔥 面试追问点

#### 1️⃣ 为什么SJF是最优的？（⭐⭐⭐⭐⭐ 必问）

```
答案：SJF的平均等待时间最短

证明：
假设有n个作业，执行时间为t1, t2, ..., tn
按SJF排序后：t1 ≤ t2 ≤ ... ≤ tn

总等待时间 = 0*t1 + 1*t2 + 2*t3 + ... + (n-1)*tn
           = Σ(i-1)*ti

如果交换任意两个作业i, j (i < j, ti > tj)
总等待时间会增加

因此，按时间递增排序(SJF)总等待时间最短。

实际例子：
FCFS: P1(10) → P2(1) → P3(1)
等待时间: 0 + 10 + 11 = 21

SJF:  P2(1) → P3(1) → P1(10)
等待时间: 0 + 1 + 2 = 3

减少了 21 - 3 = 18ms
```

#### 2️⃣ 时间片大小如何选择？（⭐⭐⭐⭐⭐ 高频）

```
考虑因素：

1. 上下文切换开销
   switch_time = 1ms
   quantum太小 → 切换开销占比大

2. 响应时间
   quantum太大 → 响应时间长

3. 吞吐量
   quantum太小 → 吞吐量低

经验公式：
quantum = (80% 进程CPU突发时间)

典型值：
- Linux: 100ms (HZ=100)
- Windows: 20ms
- 实时系统: 1ms

选择准则：
上下文切换开销 < 1%
quantum > 100 * switch_time

示例：
switch_time = 1ms
quantum = 100ms
开销占比 = 1 / 100 = 1% ✅
```

#### 3️⃣ 如何避免优先级调度的饥饿问题？（⭐⭐⭐⭐⭐ 必问）

```cpp
// 方法1：优先级老化(Aging)
void aging_scheduler() {
    for (auto& proc : ready_queue) {
        if (proc.wait_time > MAX_WAIT) {
            proc.priority++;  // 提升优先级
        }
    }
}

// 方法2：时间片轮转 + 优先级
// 每个优先级队列内部使用RR

// 方法3：多级反馈队列
// 长时间等待的进程自动提升队列级别

// Linux实现：
// CFS保证每个进程都能获得CPU时间
// 即使nice值很低，vruntime最终也会成为最小

// 实时进程vs普通进程：
// - 实时进程：SCHED_FIFO, SCHED_RR (优先级0-99)
// - 普通进程：SCHED_NORMAL (nice -20~19)
// 实时进程总是优先于普通进程
```

### 🎓 面试回答模板

```
【标准回答】
进程调度算法主要有5种：

1. FCFS(先来先服务)
   - 最简单，按到达顺序调度
   - 缺点：平均等待时间长，护航效应

2. SJF(最短作业优先)
   - 平均等待时间最短(理论最优)
   - 缺点：需要预知时间，长作业饥饿

3. 时间片轮转(RR)
   - 每个进程分配固定时间片
   - 公平，响应快
   - 缺点：时间片选择困难

4. 优先级调度
   - 灵活，支持实时系统
   - 缺点：低优先级进程饥饿

5. 多级反馈队列(MLFQ)
   - 现代OS常用(Linux CFS)
   - 综合多种策略，自适应
   - 短进程响应快，长进程不饥饿

【追问-哪种最好】
没有绝对最好的算法，取决于场景：
- 批处理系统：SJF
- 分时系统：RR
- 实时系统：优先级调度
- 通用OS：MLFQ/CFS

【追问-Linux用什么】
Linux使用CFS(完全公平调度器)：
- 维护虚拟运行时间vruntime
- 用红黑树管理进程
- 总是调度vruntime最小的进程
- O(log n)复杂度，完全公平
```

### ⚠️ 常见误区

❌ **错误1**：FCFS平均等待时间最短
✅ **正确**：SJF平均等待时间最短(理论最优)

❌ **错误2**：时间片越小越好
✅ **正确**：太小导致上下文切换开销大，需要权衡

❌ **错误3**：优先级调度没有饥饿问题
✅ **正确**：低优先级进程可能饥饿，需要老化机制

### 🌟 加分点

- 提到SJF最优性的数学证明
- 知道Linux CFS的实现原理(红黑树、vruntime)
- 了解实时调度算法(EDF、RM)
- 提到时间片大小的选择公式
- 知道多级反馈队列的自适应特性

---

## 内存管理

## 📌 虚拟内存(Virtual Memory)（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **虚拟地址** | **物理地址** | **MMU** | **页表(Page Table)** | **TLB** | **地址转换** | **按需分页** | **内存保护**

### ✅ 核心概念

**虚拟内存的本质：**
```
程序看到的地址(虚拟地址) ≠ 实际物理内存地址

进程A虚拟地址空间        物理内存
┌──────────────┐        ┌──────────────┐
│  0xFFFFFFFF  │        │              │
│  内核空间    │ ──映射→│   物理页面    │
├──────────────┤        ├──────────────┤
│              │        │              │
│   栈         │ ──┐    │   物理页面    │
│              │   │    ├──────────────┤
│   堆         │   └──→ │   物理页面    │
│              │        ├──────────────┤
│   数据段     │ ──映射→│   物理页面    │
│   代码段     │        │              │
│  0x00000000  │        └──────────────┘
└──────────────┘

进程B虚拟地址空间
┌──────────────┐
│  0xFFFFFFFF  │        同样映射到物理内存
│              │        但映射关系不同
│   栈         │ ────→  (不同的物理页面)
│   堆         │
│   ...        │
└──────────────┘

🔑 每个进程都认为自己拥有完整的地址空间
🔑 实际上共享有限的物理内存
```

### 💡 地址转换机制（⭐⭐⭐⭐⭐ 必问）

**虚拟地址到物理地址的转换：**

```cpp
// 虚拟地址结构（32位系统，4KB页面）
虚拟地址(32位)
┌────────────────┬────────────────┐
│  页号(20位)    │  页内偏移(12位)│
└────────────────┴────────────────┘
     2^20页            4KB = 2^12

// 转换过程
1. CPU生成虚拟地址: 0x00403004
   页号 = 0x403 (前20位)
   偏移 = 0x004 (后12位)

2. MMU查页表
   页表[0x403] = 物理页框号 0x2F

3. 计算物理地址
   物理地址 = (0x2F << 12) | 0x004
            = 0x0002F004

// 🔑 关键组件
CPU → 虚拟地址 → MMU → 页表查询 → 物理地址 → 物理内存
                  ↓
                 TLB缓存
```

**页表结构：**

```cpp
// 单级页表（简单但浪费空间）
struct PageTableEntry {
    bool valid;         // 有效位
    bool dirty;         // 脏位(是否被修改)
    bool accessed;      // 访问位
    bool writable;      // 可写
    bool user;          // 用户态可访问
    uint32_t frame;     // 物理页框号
};

// 32位系统，4KB页面
页表大小 = 2^20 项 × 4字节 = 4MB
// ❌ 问题：每个进程都需要4MB页表，太大！

// ✅ 解决：多级页表
// 两级页表结构（x86-32）
虚拟地址(32位)
┌──────────┬──────────┬────────────┐
│页目录索引 │页表索引  │  页内偏移  │
│  (10位)  │ (10位)   │   (12位)   │
└──────────┴──────────┴────────────┘

转换过程：
1. 页目录基址寄存器(CR3) → 页目录
2. 页目录[页目录索引] → 页表基址
3. 页表[页表索引] → 物理页框号
4. (物理页框号 << 12) | 页内偏移 = 物理地址

// 🔑 优势：
// 只需分配实际使用的页表
// 空洞部分的页表不分配
```

### 🎓 面试回答模板

```
【标准回答】（60秒版本）

虚拟内存是操作系统提供的抽象机制，让每个进程都认为
自己拥有独立完整的地址空间。

核心机制：
1. 地址转换
   - CPU生成虚拟地址
   - MMU通过页表转换为物理地址
   - TLB缓存加速转换过程

2. 页表结构
   - 多级页表节省内存
   - 页表项包含物理页框号和控制位
   - 每个进程有独立的页表

3. 主要优势
   - 内存保护：进程隔离，防止互相干扰
   - 简化编程：统一的地址空间
   - 支持大地址空间：按需分页
   - 内存共享：动态库、写时复制
```

---

## 📌 页面置换算法（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **缺页中断** | **FIFO** | **LRU** | **Clock算法** | **LFU** | **Belady异常** | **工作集** | **抖动(Thrashing)**

### ✅ 核心概念

**缺页中断(Page Fault)：**
```
场景：访问的页面不在物理内存中

1. CPU访问虚拟地址
2. MMU查页表，发现present=0（页面不在内存）
3. 触发缺页中断
4. OS选择一个物理页框（可能需要置换）
5. 从磁盘加载页面到物理内存
6. 更新页表
7. 重新执行访问指令

🔑 关键：需要选择置换哪个页面
目标：最小化缺页率
```

### 💻 四种经典算法对比

| 算法 | 实现难度 | 缺页率 | 特点 | 是否最优 |
|------|---------|--------|------|---------|
| **FIFO** | 简单 | 高 | 先进先出，可能淘汰常用页 | ❌ 有Belady异常 |
| **LRU** | 困难 | 低 | 最近最少使用，接近最优 | ✅ 理论较优 |
| **Clock** | 中等 | 中 | LRU的近似，硬件支持 | ✅ 实用 |
| **LFU** | 中等 | 中 | 最不常用，考虑访问频率 | ❌ 历史依赖 |

### 💡 FIFO（先进先出）（⭐⭐⭐⭐）

```cpp
// 实现：队列
class FIFOPageReplacement {
    queue<int> page_queue;  // 页面队列
    unordered_set<int> pages;  // 快速查找
    int capacity;

public:
    int replace(int new_page) {
        if (pages.count(new_page)) {
            return -1;  // 命中，无需置换
        }

        if (pages.size() >= capacity) {
            // 淘汰队首页面
            int victim = page_queue.front();
            page_queue.pop();
            pages.erase(victim);
        }

        // 加入新页面
        page_queue.push(new_page);
        pages.insert(new_page);
        return new_page;  // 缺页
    }
};

// 示例
访问序列: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
物理页框数: 3

时间 访问 物理页框      缺页?
1    1    [1]           ✅
2    2    [1,2]         ✅
3    3    [1,2,3]       ✅
4    4    [2,3,4]       ✅ (淘汰1)
5    1    [3,4,1]       ✅ (淘汰2)
6    2    [4,1,2]       ✅ (淘汰3)
7    5    [1,2,5]       ✅ (淘汰4)
8    1    [1,2,5]       ❌ (命中)
9    2    [1,2,5]       ❌ (命中)
10   3    [2,5,3]       ✅ (淘汰1)
11   4    [5,3,4]       ✅ (淘汰2)
12   5    [5,3,4]       ❌ (命中)

总缺页：9次
```

**Belady异常（⭐⭐⭐⭐⭐ 必考）：**
```
反直觉现象：增加物理页框数，缺页率反而上升

访问序列: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

3个页框：
[1]   [2]   [3]   [4]   [1]   [2]   [5]   [1]   [2]   [3]   [4]   [5]
1     1,2   1,2,3 2,3,4 3,4,1 4,1,2 1,2,5 1,2,5 1,2,5 2,5,3 5,3,4 5,3,4
✅    ✅    ✅    ✅    ✅    ✅    ✅    ❌    ❌    ✅    ✅    ❌
缺页：9次

4个页框：
[1]   [2]   [3]   [4]   [1]   [2]   [5]   [1]   [2]   [3]   [4]   [5]
1     1,2   1,2,3 1,2,3,4 1,2,3,4 1,2,3,4 2,3,4,5 2,3,4,5 2,3,4,5 3,4,5,3 4,5,3,4 5,3,4,5
✅    ✅    ✅    ✅    ❌    ❌    ✅    ❌    ❌    ❌    ❌    ✅
缺页：10次（更多！）

🔑 只有FIFO、随机等算法有Belady异常
🔑 LRU、LFU等栈算法没有Belady异常
```

### 💡 LRU（最近最少使用）（⭐⭐⭐⭐⭐ 必考、最优）

```cpp
// 实现1：哈希表 + 双向链表
class LRUCache {
    struct Node {
        int key, value;
        Node *prev, *next;
    };

    unordered_map<int, Node*> map;
    Node *head, *tail;
    int capacity;

public:
    LRUCache(int cap) : capacity(cap) {
        head = new Node();
        tail = new Node();
        head->next = tail;
        tail->prev = head;
    }

    int get(int key) {
        if (!map.count(key)) return -1;

        // 🔑 移到链表头（最近使用）
        Node* node = map[key];
        remove(node);
        addToHead(node);

        return node->value;
    }

    void put(int key, int value) {
        if (map.count(key)) {
            Node* node = map[key];
            node->value = value;
            remove(node);
            addToHead(node);
        } else {
            Node* node = new Node{key, value, nullptr, nullptr};

            if (map.size() >= capacity) {
                // 🔑 淘汰链表尾（最久未使用）
                Node* victim = tail->prev;
                remove(victim);
                map.erase(victim->key);
                delete victim;
            }

            addToHead(node);
            map[key] = node;
        }
    }

private:
    void remove(Node* node) {
        node->prev->next = node->next;
        node->next->prev = node->prev;
    }

    void addToHead(Node* node) {
        node->next = head->next;
        node->prev = head;
        head->next->prev = node;
        head->next = node;
    }
};

// 时间复杂度：O(1)
// 空间复杂度：O(capacity)
```

**LRU示例：**
```
访问序列: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
物理页框数: 3

时间 访问 物理页框(最近→最久)  缺页?
1    1    [1]                   ✅
2    2    [2,1]                 ✅
3    3    [3,2,1]               ✅
4    4    [4,3,2]               ✅ (淘汰1)
5    1    [1,4,3]               ✅ (淘汰2)
6    2    [2,1,4]               ✅ (淘汰3)
7    5    [5,2,1]               ✅ (淘汰4)
8    1    [1,5,2]               ❌ (命中，移到头部)
9    2    [2,1,5]               ❌ (命中，移到头部)
10   3    [3,2,1]               ✅ (淘汰5)
11   4    [4,3,2]               ✅ (淘汰1)
12   5    [5,4,3]               ✅ (淘汰2)

总缺页：10次（比FIFO少）
```

### 💡 Clock算法（时钟/二次机会）（⭐⭐⭐⭐⭐ 实用）

```cpp
// LRU的近似算法，硬件支持
// 利用页表项的accessed位

class ClockPageReplacement {
    struct Page {
        int frame;
        bool accessed;  // 硬件自动设置
    };

    vector<Page> pages;
    int hand;  // 时钟指针
    int capacity;

public:
    int replace(int new_page) {
        while (true) {
            Page& current = pages[hand];

            if (!current.accessed) {
                // 🔑 accessed=0，选中淘汰
                int victim = current.frame;
                current.frame = new_page;
                current.accessed = true;
                hand = (hand + 1) % capacity;
                return victim;
            } else {
                // 🔑 accessed=1，给第二次机会，清零
                current.accessed = false;
                hand = (hand + 1) % capacity;
            }
        }
    }
};

// 可视化
环形缓冲区：
┌───┬───┬───┬───┐
│ 1 │ 2 │ 3 │ 4 │
│ 1 │ 1 │ 0 │ 1 │ ← accessed位
└───┴───┴───┴───┘
      ↑
     hand（时钟指针）

置换过程：
1. hand指向2，accessed=1 → 设为0，hand++
2. hand指向3，accessed=0 → 选中淘汰！

🔑 优点：
- 近似LRU，性能接近
- 硬件支持（MMU自动设置accessed位）
- 实现简单（Linux使用）
```

### 🔥 面试追问点

#### 1️⃣ 为什么LRU接近最优？（⭐⭐⭐⭐⭐ 必问）

```
理论依据：局部性原理(Locality)

1. 时间局部性
   最近访问的页面很可能再次被访问
   示例：循环中的代码页面

2. 空间局部性
   访问某地址后，附近地址也可能被访问
   示例：数组遍历

LRU利用时间局部性：
✅ 保留最近使用的页面
✅ 淘汰最久未使用的页面（未来可能不用）

理论最优：OPT（Optimal）
淘汰未来最长时间不使用的页面
❌ 需要预知未来，实际不可实现
✅ LRU是实际可实现的最接近OPT的算法

实验数据：
OPT:  缺页率5%   (理论下限)
LRU:  缺页率8%   (接近最优)
FIFO: 缺页率15%  (较差)
```

#### 2️⃣ LRU实现开销大，如何优化？（⭐⭐⭐⭐⭐ 高频）

```cpp
问题：
- 精确LRU需要每次访问都更新链表
- 开销大，不适合OS内核

解决方案：

1. Clock算法（⭐最常用）
   利用硬件accessed位
   近似LRU，开销小

2. NRU（Not Recently Used）
   4个类别：
   (accessed, dirty)
   (0, 0) - 最优淘汰对象
   (0, 1)
   (1, 0)
   (1, 1) - 最差淘汰对象

   选择类别最小的页面淘汰

3. 分段LRU
   将内存分成若干段
   每段独立LRU
   减少全局搜索开销

4. 多级队列
   活跃队列 + 非活跃队列
   定期降级，类似MLFQ思想

Linux实际使用：
- 双链表LRU
  - active_list（活跃页面）
  - inactive_list（非活跃页面）
- 定期扫描，降级页面
- 使用accessed位辅助判断
```

#### 3️⃣ 什么是抖动(Thrashing)？如何避免？（⭐⭐⭐⭐⭐ 核心）

```cpp
抖动：进程频繁缺页，大部分时间在换页

场景：
进程工作集 = 100页（实际需要的页面数）
分配物理页框 = 50页
→ 不断缺页，不断置换
→ CPU利用率极低

┌────────────────────────────────┐
│ CPU利用率                       │
│ 100%                            │
│                                 │
│  50% ──────────┐               │
│                │  ↓ 抖动区      │
│                └────────────    │
│  0%                             │
└────────────────────────────────┘
  少←─ 进程数量 ─→ 多

解决方案：

1. 工作集模型(Working Set)
   定义：进程在Δ时间内访问的页面集合

   工作集大小 = W(t, Δ)
   示例：过去10秒访问的页面

   策略：
   if (工作集大小 > 分配页框数) {
       挂起进程或增加内存;
   }

2. 缺页率控制
   if (缺页率 > 上限) {
       增加页框;
   }
   if (缺页率 < 下限) {
       减少页框;
   }

3. 页面锁定
   关键页面（内核、驱动）不换出

4. 调整多道程序度
   减少并发进程数量
   宁可CPU空闲，不要抖动

🔑 本质：
给每个进程足够的物理内存
否则宁可减少进程数量
```

#### 4️⃣ 写时复制(Copy-on-Write)的原理？（⭐⭐⭐⭐ 加分项）

```cpp
// fork()优化：不立即复制内存

// 传统fork：
pid_t pid = fork();
// ❌ 立即复制父进程所有页面
// 耗时，浪费（子进程可能立即exec）

// COW优化：
pid_t pid = fork();
// ✅ 父子进程共享物理页面
// 页面标记为只读

// 当任一进程写入时：
父进程: write(addr)
→ 触发写保护异常
→ OS分配新页面
→ 复制内容
→ 更新页表（标记可写）
→ 继续执行

实现：
1. fork时
   - 子进程页表指向父进程页面
   - 所有页面标记为只读
   - 引用计数+1

2. 写入时
   if (ref_count == 1) {
       // 只有一个引用，直接标记可写
       page->writable = true;
   } else {
       // 多个引用，复制页面
       new_page = copy_page(page);
       update_page_table(new_page);
       page->ref_count--;
   }

性能提升：
传统fork: 复制100MB → 耗时100ms
COW fork:  标记只读 → 耗时1ms（提升100倍）
```

### 🎓 面试回答模板

```
【标准回答】

页面置换算法用于选择淘汰哪个页面。常见算法：

1. FIFO（先进先出）
   - 简单，按进入时间淘汰
   - 有Belady异常（增加页框反而缺页更多）

2. LRU（最近最少使用）
   - 淘汰最久未使用的页面
   - 理论接近最优，但实现开销大
   - 通常用哈希表+双向链表实现

3. Clock算法
   - LRU的近似，利用硬件accessed位
   - 实现简单，Linux等OS实际使用
   - 给页面"第二次机会"

4. LFU（最不常用）
   - 淘汰访问频率最低的页面
   - 考虑历史访问，适合某些场景

【追问-为何LRU最优】
LRU利用了时间局部性原理，最近访问的页面未来也可能访问。
理论最优是OPT（淘汰未来最晚使用的），但需要预知未来。
LRU是实际可实现的最接近OPT的算法。

【追问-如何实现LRU】
精确LRU：哈希表+双向链表，O(1)操作
近似LRU：Clock算法，利用硬件accessed位
Linux使用双链表LRU（active_list + inactive_list）

【追问-抖动】
抖动是进程频繁缺页，大部分时间在换页。
原因：工作集大于分配页框数。
解决：工作集模型、缺页率控制、减少进程数。
```

### ⚠️ 常见误区

❌ **错误1**：LRU一定比FIFO好
✅ **正确**：大多数情况是，但某些特殊访问模式FIFO也可能更好

❌ **错误2**：增加物理内存一定减少缺页
✅ **正确**：FIFO有Belady异常，可能增加缺页

❌ **错误3**：LRU需要每次访问都更新
✅ **正确**：实际使用近似算法（Clock），定期更新

❌ **错误4**：页面置换只看访问时间
✅ **正确**：还要考虑dirty位（脏页需要写回磁盘，开销大）

### 🌟 加分点

- 知道OPT（最优页面置换）是理论下限
- 了解工作集(Working Set)模型
- 知道Linux的双链表LRU实现
- 理解写时复制(COW)的原理和应用
- 提到NUMA架构下的页面置换策略
- 了解大页(Huge Page)对置换的影响

---

## 死锁

## 📌 死锁的概念与条件（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **互斥** | **占有并等待** | **不可剥夺** | **循环等待** | **资源分配图** | **银行家算法** | **死锁预防** | **死锁避免**

### ✅ 死锁定义

```
死锁：多个进程因竞争资源而造成的一种僵局
若无外力干涉，这些进程都将永远阻塞

经典例子：
进程P1: 持有资源A，等待资源B
进程P2: 持有资源B，等待资源A
→ P1和P2相互等待，永久阻塞

哲学家就餐问题：
5个哲学家，5根筷子
每人需要左右两根筷子才能吃饭
如果每人都拿起左边的筷子，等待右边的
→ 死锁
```

### 💡 死锁的四个必要条件（⭐⭐⭐⭐⭐ 必考）

```cpp
1. 互斥(Mutual Exclusion)
   资源不能被共享，一次只能被一个进程使用

   示例：
   打印机、临界区锁

2. 占有并等待(Hold and Wait)
   进程已持有至少一个资源，并在等待获取其他资源

   示例：
   进程持有锁A，等待锁B

3. 不可剥夺(No Preemption)
   已分配的资源不能强行剥夺，只能由进程主动释放

   示例：
   进程持有的锁不能被系统强制释放

4. 循环等待(Circular Wait)
   存在进程集合{P0, P1, ..., Pn}
   P0等待P1持有的资源
   P1等待P2持有的资源
   ...
   Pn等待P0持有的资源

🔑 四个条件同时满足才会死锁
🔑 破坏任意一个条件即可避免死锁
```

**可视化循环等待：**
```
资源分配图：
┌───┐     资源A      ┌───┐
│P1 │────────────────>│ A │
└───┘                 └───┘
  ↑                     │
  │                     │
  │                     ↓
  │                   ┌───┐
  │                   │P2 │
  │                   └───┘
  │                     │
  │                     │
  │     资源B           ↓
┌───┐<──────────────┌───┐
│ B │               │   │
└───┘               └───┘

说明：
→ 表示请求资源
← 表示持有资源

P1: 持有A，请求B
P2: 持有B，请求A
形成环路 → 死锁
```

### 💻 死锁示例代码

```cpp
// 经典死锁例子
mutex mtx1, mtx2;

// 线程1
void thread1() {
    lock_guard<mutex> lock1(mtx1);  // 持有mtx1
    this_thread::sleep_for(100ms);

    lock_guard<mutex> lock2(mtx2);  // 等待mtx2
    // 临界区
}

// 线程2
void thread2() {
    lock_guard<mutex> lock2(mtx2);  // 持有mtx2
    this_thread::sleep_for(100ms);

    lock_guard<mutex> lock1(mtx1);  // 等待mtx1
    // 临界区
}

// 执行流程：
时刻1: 线程1获得mtx1
时刻2: 线程2获得mtx2
时刻3: 线程1等待mtx2（被线程2持有）
时刻4: 线程2等待mtx1（被线程1持有）
→ 死锁！
```

### 🔥 死锁处理策略

| 策略 | 方法 | 优点 | 缺点 | 适用场景 |
|------|------|------|------|---------|
| **预防** | 破坏四个条件之一 | 简单有效 | 资源利用率低 | 嵌入式系统 |
| **避免** | 银行家算法等 | 资源利用率高 | 需要预知需求 | 已知资源需求 |
| **检测+恢复** | 定期检测环路 | 资源利用率高 | 有开销 | 大型系统 |
| **鸵鸟策略** | 忽略死锁 | 无开销 | 可能死锁 | 死锁概率极低的系统 |

---

## 📌 死锁预防（⭐⭐⭐⭐⭐ 必考）

### 🎯 核心思想
> 破坏死锁的四个必要条件之一

### 💡 四种预防方法

#### 1️⃣ 破坏互斥条件（⭐⭐）

```cpp
// ❌ 通常不可行
// 原因：很多资源本身就是互斥的（打印机、临界区等）

// 可行的例子：假脱机技术(SPOOLing)
// 将独占设备改造成共享设备

// 打印机的SPOOLing
void print(string content) {
    // 不直接操作打印机
    // 而是写入假脱机文件
    spool_file.write(content);
}

// 单独的打印守护进程
void printer_daemon() {
    while (true) {
        if (spool_file.has_content()) {
            real_print(spool_file.read());
        }
    }
}

// 🔑 多个进程可以"同时"打印
// 实际上是写入不同的假脱机文件
// 打印机只被守护进程独占
```

#### 2️⃣ 破坏占有并等待（⭐⭐⭐⭐⭐ 重要）

```cpp
// 方法1：一次性申请所有资源
class ResourceManager {
public:
    bool allocate_all(Process* p, vector<Resource*> res_list) {
        // 🔑 原子操作：要么全部获得，要么一个也不获得
        lock_guard<mutex> lock(global_mutex);

        // 检查所有资源是否可用
        for (auto& res : res_list) {
            if (res->is_allocated()) {
                return false;  // 有资源不可用，直接返回
            }
        }

        // 全部可用，一次性分配
        for (auto& res : res_list) {
            res->allocate_to(p);
        }

        return true;
    }
};

// ❌ 缺点：
// 1. 资源利用率低（一次性占用，但可能不立即使用）
// 2. 可能饥饿（某进程需要的资源多，长时间得不到）

// 方法2：释放已有资源再申请
bool try_acquire(mutex& m1, mutex& m2) {
    unique_lock<mutex> lock1(m1);

    if (!m2.try_lock()) {
        // 无法获得m2
        lock1.unlock();  // 🔑 释放已持有的m1
        return false;
    }

    // 成功获得两个锁
    return true;
}

// C++17 scoped_lock (自动原子获取多个锁)
void safe_function() {
    scoped_lock lock(mtx1, mtx2, mtx3);  // 原子操作
    // 临界区
}
```

#### 3️⃣ 破坏不可剥夺（⭐⭐⭐⭐）

```cpp
// 方法：允许抢占资源

// 实现1：主动释放
bool acquire_with_timeout(mutex& m, int timeout_ms) {
    auto start = chrono::steady_clock::now();

    while (!m.try_lock()) {
        auto now = chrono::steady_clock::now();
        auto elapsed = chrono::duration_cast<chrono::milliseconds>(now - start);

        if (elapsed.count() > timeout_ms) {
            // 超时，释放已持有的资源
            release_all_resources();
            return false;
        }

        this_thread::sleep_for(10ms);
    }

    return true;
}

// 实现2：优先级抢占（实时系统）
class PreemptiveResource {
    Process* owner;
    int priority;

public:
    bool acquire(Process* p) {
        if (owner && p->priority > owner->priority) {
            // 🔑 新进程优先级更高，抢占资源
            owner->save_state();  // 保存状态
            owner->rollback();    // 回滚
            owner = p;
            return true;
        }
        return false;
    }
};

// ⚠️ 适用场景：
// ✅ 状态易于保存和恢复的资源（CPU、内存）
// ❌ 不适合打印机等不可中断的资源
```

#### 4️⃣ 破坏循环等待（⭐⭐⭐⭐⭐ 最常用）

```cpp
// 方法：资源有序分配

// 给所有资源编号
enum ResourceID {
    LOCK_A = 1,
    LOCK_B = 2,
    LOCK_C = 3,
    FILE_X = 4,
    FILE_Y = 5
};

// 规则：必须按编号递增顺序申请资源
class OrderedResourceManager {
    map<ResourceID, mutex*> resources;

public:
    void acquire_in_order(vector<ResourceID> res_list) {
        // 🔑 排序，保证按编号递增顺序
        sort(res_list.begin(), res_list.end());

        for (auto id : res_list) {
            resources[id]->lock();
        }
    }
};

// 示例：避免死锁
mutex mtx1, mtx2;  // 编号：1, 2

// ✅ 正确：都按1→2顺序
void thread_A() {
    lock_guard<mutex> lock1(mtx1);  // 先锁1
    lock_guard<mutex> lock2(mtx2);  // 再锁2
}

void thread_B() {
    lock_guard<mutex> lock1(mtx1);  // 先锁1
    lock_guard<mutex> lock2(mtx2);  // 再锁2
}

// ❌ 错误：不同顺序
void thread_A_bad() {
    lock_guard<mutex> lock1(mtx1);  // 先锁1
    lock_guard<mutex> lock2(mtx2);  // 再锁2
}

void thread_B_bad() {
    lock_guard<mutex> lock2(mtx2);  // 先锁2 ❌
    lock_guard<mutex> lock1(mtx1);  // 再锁1 ❌
}

// 🔑 为什么有序分配能避免循环等待？
// 假设P1持有资源i，等待资源j（j > i）
// P2持有资源j，则P2只能等待资源k（k > j > i）
// P2不可能等待资源i
// 因此不会形成环路
```

### 🎓 预防方法总结

```
方法              破坏条件        可行性    资源利用率
────────────────────────────────────────────
SPOOLing         互斥           低        中
一次性申请       占有并等待      高        低
资源抢占         不可剥夺        中        中
有序资源分配     循环等待        ⭐高      ⭐高

🔑 实际常用：
1. 有序资源分配（最实用）
2. 超时释放（破坏占有并等待）
3. try_lock + 重试
```

---

## 📌 死锁避免 - 银行家算法（⭐⭐⭐⭐⭐ 必考）

### 🎯 核心思想
> 动态检查资源分配状态，确保系统始终处于安全状态

### ✅ 关键概念

```cpp
// 数据结构
int n;  // 进程数
int m;  // 资源类型数

// Available: 可用资源向量
vector<int> Available(m);

// Max: 最大需求矩阵
vector<vector<int>> Max(n, vector<int>(m));

// Allocation: 已分配矩阵
vector<vector<int>> Allocation(n, vector<int>(m));

// Need: 还需要矩阵
vector<vector<int>> Need(n, vector<int>(m));
// Need[i][j] = Max[i][j] - Allocation[i][j]

// 安全状态：存在一个进程序列，使每个进程都能完成
// 不安全状态：不一定死锁，但可能死锁
```

### 💻 银行家算法实现

```cpp
class BankersAlgorithm {
    int n, m;  // n个进程，m种资源
    vector<int> Available;
    vector<vector<int>> Max, Allocation, Need;

public:
    // 🔑 安全性检查算法
    bool is_safe() {
        vector<int> Work = Available;  // 工作向量
        vector<bool> Finish(n, false); // 完成标记
        vector<int> safe_sequence;     // 安全序列

        // 寻找安全序列
        int count = 0;
        while (count < n) {
            bool found = false;

            for (int i = 0; i < n; i++) {
                if (Finish[i]) continue;

                // 🔑 检查进程i是否能完成
                bool can_finish = true;
                for (int j = 0; j < m; j++) {
                    if (Need[i][j] > Work[j]) {
                        can_finish = false;
                        break;
                    }
                }

                if (can_finish) {
                    // 进程i可以完成
                    for (int j = 0; j < m; j++) {
                        Work[j] += Allocation[i][j];  // 释放资源
                    }
                    Finish[i] = true;
                    safe_sequence.push_back(i);
                    found = true;
                    count++;
                    break;
                }
            }

            if (!found) {
                // 找不到可完成的进程
                return false;  // 不安全
            }
        }

        // 找到安全序列
        print_safe_sequence(safe_sequence);
        return true;
    }

    // 🔑 资源请求算法
    bool request_resources(int pid, vector<int>& request) {
        // 1. 检查请求是否合法
        for (int j = 0; j < m; j++) {
            if (request[j] > Need[pid][j]) {
                cerr << "请求超过需求!" << endl;
                return false;
            }
            if (request[j] > Available[j]) {
                cerr << "资源不足，需要等待!" << endl;
                return false;
            }
        }

        // 2. 试探性分配
        for (int j = 0; j < m; j++) {
            Available[j] -= request[j];
            Allocation[pid][j] += request[j];
            Need[pid][j] -= request[j];
        }

        // 3. 安全性检查
        if (is_safe()) {
            // 安全，分配成功
            return true;
        } else {
            // 不安全，回滚
            for (int j = 0; j < m; j++) {
                Available[j] += request[j];
                Allocation[pid][j] -= request[j];
                Need[pid][j] += request[j];
            }
            return false;
        }
    }
};
```

### 📊 银行家算法示例

```
示例：5个进程，3种资源(A, B, C)

初始状态：
Available = [3, 3, 2]

       Max      Allocation    Need
     A  B  C    A  B  C      A  B  C
P0   7  5  3    0  1  0      7  4  3
P1   3  2  2    2  0  0      1  2  2
P2   9  0  2    3  0  2      6  0  0
P3   2  2  2    2  1  1      0  1  1
P4   4  3  3    0  0  2      4  3  1

🔑 寻找安全序列：

步骤1：找能完成的进程
- P0: Need=[7,4,3] > Available=[3,3,2] ❌
- P1: Need=[1,2,2] > Available=[3,3,2] ❌
- P2: Need=[6,0,0] > Available=[3,3,2] ❌
- P3: Need=[0,1,1] ≤ Available=[3,3,2] ✅
  执行P3，释放资源
  Available = [3,3,2] + [2,1,1] = [5,4,3]

步骤2：
- P0: Need=[7,4,3] > Available=[5,4,3] ❌
- P1: Need=[1,2,2] ≤ Available=[5,4,3] ✅
  执行P1，释放资源
  Available = [5,4,3] + [2,0,0] = [7,4,3]

步骤3：
- P0: Need=[7,4,3] ≤ Available=[7,4,3] ✅
  执行P0，释放资源
  Available = [7,4,3] + [0,1,0] = [7,5,3]

步骤4：
- P2: Need=[6,0,0] ≤ Available=[7,5,3] ✅
  执行P2，释放资源
  Available = [7,5,3] + [3,0,2] = [10,5,5]

步骤5：
- P4: Need=[4,3,1] ≤ Available=[10,5,5] ✅
  执行P4

安全序列: P3 → P1 → P0 → P2 → P4
系统处于安全状态 ✅
```

### 🔥 面试追问点

#### 1️⃣ 安全状态和不安全状态的区别？（⭐⭐⭐⭐⭐ 必问）

```
安全状态(Safe State)：
- 存在一个进程序列，使所有进程都能完成
- 可以找到至少一个安全序列
- 一定不会死锁

不安全状态(Unsafe State)：
- 找不到安全序列
- 不一定死锁，但可能死锁
- 是死锁的必要非充分条件

关系：
┌────────────────────────────┐
│  所有状态                   │
│  ┌──────────────────┐      │
│  │  安全状态         │      │
│  │  ✅不会死锁       │      │
│  └──────────────────┘      │
│         │                  │
│  ┌──────▼───────────┐      │
│  │  不安全状态       │      │
│  │  ❓可能死锁      │      │
│  │  ┌───────────┐   │      │
│  │  │死锁状态    │   │      │
│  │  │❌一定死锁  │   │      │
│  │  └───────────┘   │      │
│  └──────────────────┘      │
└────────────────────────────┘

示例：
3个进程，12个资源

状态1（安全）：
P0持有5，需要5  → 可以完成（可用7）
P1持有2，需要2  → 可以完成
P2持有2，需要6  → 可以完成
安全序列: P0→P1→P2

状态2（不安全但未死锁）：
P0持有5，需要6  → 无法完成（可用1）
P1持有4，需要5  → 无法完成
P2持有2，需要4  → 无法完成
找不到安全序列，但如果P0主动释放，可恢复
```

#### 2️⃣ 银行家算法的缺点？（⭐⭐⭐⭐）

```cpp
缺点：

1. 必须预知最大需求
   ❌ 实际中很难准确预知
   示例：编译器可能需要打开多少文件？

2. 进程数固定
   ❌ 实际中进程动态创建和销毁

3. 资源数固定
   ❌ 实际中资源可能增减（插拔USB）

4. 运行开销大
   ❌ 每次请求都要检查安全性
   ❌ O(n*m) 复杂度

5. 不能长时间占用
   ❌ 假设进程会在有限时间内释放资源
   ❌ 实际中可能长时间持有

实际应用：
✅ 资源有限且已知的小型嵌入式系统
❌ 大型通用操作系统（Linux/Windows不用）
```

### 🎓 面试回答模板

```
【标准回答】

银行家算法是一种死锁避免算法，核心思想是：
在资源分配前检查是否会进入不安全状态。

关键数据结构：
- Available: 可用资源
- Max: 最大需求
- Allocation: 已分配
- Need: 还需要 = Max - Allocation

算法步骤：
1. 检查请求是否合法（不超过需求和可用）
2. 试探性分配资源
3. 运行安全性检查算法
   - 寻找能完成的进程
   - 模拟该进程完成并释放资源
   - 重复直到所有进程完成或找不到
4. 如果安全，真正分配；否则回滚

安全状态：能找到安全序列，一定不死锁
不安全状态：找不到安全序列，可能死锁

【追问-为何实际不常用】
1. 需要预知最大需求（实际很难）
2. 进程和资源数动态变化
3. 运行开销大（每次请求都检查）
4. 限制了并发度（资源利用率不高）
```

### ⚠️ 常见误区

❌ **错误1**：不安全状态就是死锁状态
✅ **正确**：不安全状态可能死锁，死锁状态一定不安全

❌ **错误2**：银行家算法能检测死锁
✅ **正确**：银行家算法是避免死锁，不是检测死锁

❌ **错误3**：安全序列是唯一的
✅ **正确**：可能有多个安全序列

### 🌟 加分点

- 能手写银行家算法的核心代码
- 知道银行家算法的时间复杂度O(n²m)
- 了解资源分配图检测死锁的方法
- 提到Linux等OS不使用银行家算法的原因
- 知道死锁检测和恢复的策略

---

## 文件系统

## 📌 文件系统基础（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **inode** | **目录项** | **文件描述符** | **硬链接** | **软链接** | **文件分配** | **磁盘调度** | **页缓存**

### ✅ 文件系统层次结构

```
应用层
  │
  ├─ open(), read(), write(), close()
  │
系统调用层
  │
  ├─ VFS（虚拟文件系统）
  │    ├─ 统一接口
  │    └─ 支持多种文件系统（ext4, NTFS, FAT32等）
  │
具体文件系统层（如ext4）
  │
  ├─ inode管理
  ├─ 目录管理
  ├─ 磁盘块管理
  │
块设备层
  │
  ├─ 页缓存（Page Cache）
  ├─ I/O调度
  │
磁盘驱动层
  │
  └─ 物理磁盘
```

### 💡 inode详解（⭐⭐⭐⭐⭐ 核心）

**什么是inode？**

```cpp
// inode：索引节点，存储文件元数据

struct inode {
    // 🔑 文件元数据（不包含文件名！）
    mode_t i_mode;        // 文件类型和权限
    uid_t i_uid;          // 所有者ID
    gid_t i_gid;          // 组ID
    off_t i_size;         // 文件大小
    time_t i_atime;       // 最后访问时间
    time_t i_mtime;       // 最后修改时间
    time_t i_ctime;       // inode变化时间

    // 🔑 数据块索引（核心！）
    block_t i_block[15];  // 数据块指针
    /*
    i_block[0..11]   : 直接块（12个）
    i_block[12]      : 一级间接块
    i_block[13]      : 二级间接块
    i_block[14]      : 三级间接块
    */

    int i_links_count;    // 硬链接计数
};
```

**inode数据块索引机制：**

```
文件大小寻址方式：

小文件（< 48KB）：
┌─────────────┐
│ inode       │
│ i_block[0]  │──→ 数据块1（4KB）
│ i_block[1]  │──→ 数据块2（4KB）
│ ...         │
│ i_block[11] │──→ 数据块12（4KB）
└─────────────┘
总共：12 × 4KB = 48KB

中文件（48KB - 4MB）：
┌─────────────┐
│ inode       │
│ i_block[12] │──→ 一级间接块
└─────────────┘      │
                     ├──→ 数据块1
                     ├──→ 数据块2
                     │    ...
                     └──→ 数据块1024
一级间接：1024 × 4KB = 4MB

大文件（4MB - 4GB）：
┌─────────────┐
│ inode       │
│ i_block[13] │──→ 二级间接块
└─────────────┘      │
                     ├──→ 一级间接块1
                     │     ├──→ 数据块...
                     │     └──→ 1024个数据块
                     ├──→ 一级间接块2
                     │     └──→ 1024个数据块
                     ...
二级间接：1024 × 1024 × 4KB = 4GB

超大文件（4GB+）：
三级间接：1024 × 1024 × 1024 × 4KB = 4TB
```

**inode查找过程：**

```cpp
// 读取文件偏移为offset的数据
void* read_file(struct inode* inode, off_t offset) {
    // 1. 计算数据块号
    int block_size = 4096;  // 4KB
    int block_num = offset / block_size;
    int block_offset = offset % block_size;

    // 2. 根据block_num选择寻址方式
    block_t physical_block;

    if (block_num < 12) {
        // 🔑 直接块
        physical_block = inode->i_block[block_num];
    }
    else if (block_num < 12 + 1024) {
        // 🔑 一级间接块
        block_t indirect = inode->i_block[12];
        int index = block_num - 12;

        // 读取间接块
        block_t* indirect_table = read_block(indirect);
        physical_block = indirect_table[index];
    }
    else if (block_num < 12 + 1024 + 1024*1024) {
        // 🔑 二级间接块
        block_t double_indirect = inode->i_block[13];
        int index = block_num - 12 - 1024;

        int first_level = index / 1024;
        int second_level = index % 1024;

        // 读取二级间接块
        block_t* first_table = read_block(double_indirect);
        block_t* second_table = read_block(first_table[first_level]);
        physical_block = second_table[second_level];
    }

    // 3. 读取物理块
    void* data = read_block(physical_block);
    return data + block_offset;
}

// 🔑 性能分析：
// 直接块：1次磁盘读取
// 一级间接：2次磁盘读取（间接块 + 数据块）
// 二级间接：3次磁盘读取
// 三级间接：4次磁盘读取
```

### 📌 目录与文件名（⭐⭐⭐⭐⭐ 必考）

**目录的本质：**

```cpp
// 目录也是文件，内容是目录项的列表

struct dir_entry {
    ino_t inode;        // 🔑 inode编号
    char name[255];     // 🔑 文件名
    uint16_t rec_len;   // 记录长度
    uint8_t name_len;   // 文件名长度
    uint8_t file_type;  // 文件类型
};

// 目录示例：
目录 /home/user/ 的内容：
┌────────────────────────────┐
│ inode: 123  name: "."      │  当前目录
│ inode: 2    name: ".."     │  父目录
│ inode: 456  name: "file1"  │
│ inode: 789  name: "dir1"   │  子目录
└────────────────────────────┘

// 🔑 关键：
// 1. 文件名存储在目录中，不在inode中
// 2. 一个inode可以有多个文件名（硬链接）
// 3. 目录的inode指向目录数据块
```

**路径解析过程：**

```
查找文件：/home/user/file.txt

1. 从根目录开始（inode=2）
   读取inode 2的数据块
   → 找到目录项 "home" → inode=50

2. 读取inode 50的数据块
   → 找到目录项 "user" → inode=100

3. 读取inode 100的数据块
   → 找到目录项 "file.txt" → inode=456

4. 读取inode 456
   → 获得文件元数据和数据块位置

总共磁盘访问：
3次目录查找 + 1次inode读取 = 4次
```

### 📌 硬链接与软链接（⭐⭐⭐⭐⭐ 高频）

**硬链接（Hard Link）：**

```bash
# 创建硬链接
ln file1.txt file2.txt

# 文件系统结构：
目录：
┌──────────────────────────┐
│ inode: 456  name: "file1.txt" │
│ inode: 456  name: "file2.txt" │  ← 🔑 指向同一个inode
└──────────────────────────┘

inode 456:
  i_links_count = 2  ← 🔑 硬链接计数
  i_size = 1024
  i_block[0] = ...

数据块：
  实际文件内容
```

**硬链接特性：**

```cpp
// 🔑 1. 删除文件的本质
void unlink(const char* filename) {
    // 1. 从目录中删除目录项
    remove_dir_entry(filename);

    // 2. inode引用计数-1
    inode->i_links_count--;

    // 3. 只有当i_links_count=0时，才真正删除数据
    if (inode->i_links_count == 0) {
        free_data_blocks(inode);
        free_inode(inode);
    }
}

// 🔑 2. 硬链接限制
// ❌ 不能跨文件系统（inode编号只在单个文件系统内有效）
// ❌ 不能链接目录（防止循环）
// ✅ 链接后文件完全等价
// ✅ 删除任一链接不影响其他
```

**软链接（Symbolic Link）：**

```bash
# 创建软链接
ln -s /home/user/file1.txt link.txt

# 文件系统结构：
目录：
┌──────────────────────────────┐
│ inode: 456  name: "file1.txt" │
│ inode: 789  name: "link.txt"  │  ← 🔑 不同的inode
└──────────────────────────────┘

inode 789:
  i_mode = S_IFLNK | 0777  ← 🔑 文件类型：符号链接
  i_size = 21              ← 路径字符串长度
  数据块内容: "/home/user/file1.txt"  ← 🔑 存储目标路径
```

**软链接特性：**

```cpp
// 🔑 软链接的访问过程
void* open_symlink(const char* linkname) {
    // 1. 读取软链接的inode
    struct inode* link_inode = get_inode(linkname);

    // 2. 检查是否为软链接
    if (S_ISLNK(link_inode->i_mode)) {
        // 3. 读取目标路径
        char target[256];
        read_data(link_inode, target, link_inode->i_size);

        // 4. 重新打开目标文件
        return open(target);  // 可能递归（软链接链软链接）
    }
}

// 🔑 软链接优势
// ✅ 可以跨文件系统
// ✅ 可以链接目录
// ✅ 可以链接不存在的文件

// ⚠️ 软链接问题
// ❌ 目标文件删除后，软链接失效（悬空链接）
// ❌ 访问需要额外查找开销
```

**对比总结：**

```
特性           硬链接                软链接
────────────────────────────────────────────
inode         相同                  不同
跨文件系统     不可以                可以
链接目录       不可以                可以
目标删除       不影响                失效
性能          无额外开销            需要额外查找
创建命令      ln file link          ln -s file link
```

### 🔥 面试追问点

#### 1️⃣ 为什么inode不存储文件名？（⭐⭐⭐⭐⭐ 高频）

```
原因：

1. 支持硬链接
   - 一个文件可以有多个文件名
   - 如果inode存文件名，无法支持多个名字

2. 简化目录操作
   - 移动文件只需修改目录项（inode不变）
   - mv /home/a.txt /tmp/b.txt
     → 只需修改目录项，inode和数据不变

3. 节省空间
   - inode固定大小（通常256字节）
   - 文件名可变长度，不适合存在inode中

示例：
┌─────────┐     ┌─────────┐
│ dir1    │     │ dir2    │
│ file1   │─┐   │ file2   │─┐
└─────────┘ │   └─────────┘ │
            ↓                ↓
          ┌─────────────────┐
          │   inode 456     │  ← 同一个inode
          │   数据：...      │
          └─────────────────┘
```

#### 2️⃣ 删除一个打开的文件会怎样？（⭐⭐⭐⭐⭐ 必问）

```cpp
// 场景：
int fd = open("file.txt", O_RDWR);
unlink("file.txt");  // 删除文件
write(fd, "data", 4);  // 🔑 仍然可以写入！

// 原理：
1. open()时：
   - 文件描述符 → inode引用
   - inode->i_count++（内核引用计数）

2. unlink()时：
   - 目录项删除
   - inode->i_links_count--（硬链接计数）
   - 🔑 但inode->i_count > 0，数据不删除

3. close(fd)时：
   - inode->i_count--
   - 🔑 当i_count=0 且 i_links_count=0时，才删除数据

// 应用：
// 临时文件技巧
int fd = open("temp.dat", O_CREAT | O_RDWR);
unlink("temp.dat");  // 立即删除目录项
// ... 使用fd读写文件
close(fd);  // 此时文件数据才真正删除

// 🔑 优势：
// - 文件不会留在磁盘上（进程崩溃也会自动清理）
// - 避免命名冲突
```

#### 3️⃣ ls -l显示的文件大小和实际占用磁盘空间为什么不同？（⭐⭐⭐⭐）

```bash
# 示例
$ echo "hello" > file.txt
$ ls -l file.txt
-rw-r--r-- 1 user user 6 Dec 4 file.txt  ← 显示6字节

$ du -h file.txt
4.0K    file.txt  ← 实际占用4KB

# 原因：

1. ls -l显示：inode->i_size（逻辑大小）
   - 实际文件内容大小：6字节

2. du显示：实际占用磁盘块
   - 磁盘分配最小单位：4KB（一个块）
   - 即使只用6字节，也占用4KB

3. 空洞文件（Sparse File）
$ dd if=/dev/zero of=sparse.dat bs=1 count=1 seek=1G
$ ls -l sparse.dat
-rw-r--r-- 1 user user 1073741825 Dec 4 sparse.dat  ← 1GB
$ du -h sparse.dat
4.0K    sparse.dat  ← 只占4KB！

// 原理：
struct inode {
    off_t i_size = 1GB;  // 逻辑大小
    block_t i_blocks = 8;  // 实际分配块数（4KB）
};

// 🔑 空洞：中间未分配的区域，读取时返回0
// 应用：虚拟机磁盘文件、数据库文件
```

### 📌 文件分配方式（⭐⭐⭐⭐）

**1. 连续分配（Contiguous Allocation）**

```
文件A：起始块=100，长度=5
┌────┬────┬────┬────┬────┐
│100 │101 │102 │103 │104 │
└────┴────┴────┴────┴────┘

✅ 优点：
- 顺序访问快（连续读取）
- 随机访问简单（块号 = 起始块 + 偏移）

❌ 缺点：
- 外部碎片严重
- 文件增长困难（需要预留空间）

应用：CD-ROM、DVD（只读，大小固定）
```

**2. 链接分配（Linked Allocation）**

```
文件B：起始块=200
┌────────┐    ┌────────┐    ┌────────┐
│ 数据   │    │ 数据   │    │ 数据   │
│ next→205│  │ next→310│  │ next=NULL│
└────────┘    └────────┘    └────────┘
  块200         块205         块310

✅ 优点：
- 无外部碎片
- 文件可动态增长

❌ 缺点：
- 随机访问慢（需要从头遍历链表）
- 可靠性差（一个块损坏，后续全丢失）
- 指针占用空间

应用：FAT文件系统（改进版：FAT表集中存储）
```

**3. 索引分配（Indexed Allocation）**

```
文件C：索引块=400
┌────────────┐
│ 索引块400  │
│ ┌────┐     │
│ │105 │     │  ──→ 数据块105
│ │207 │     │  ──→ 数据块207
│ │308 │     │  ──→ 数据块308
│ │...│     │
│ └────┘     │
└────────────┘

✅ 优点：
- 支持随机访问（通过索引直接定位）
- 无外部碎片
- 动态增长

❌ 缺点：
- 索引块开销
- 小文件浪费（也需要索引块）

🔑 这就是inode的方式！
- 多级索引解决大文件问题
- 直接块优化小文件
```

### 📌 磁盘调度算法（⭐⭐⭐⭐）

**磁盘访问时间 = 寻道时间 + 旋转延迟 + 传输时间**

```
场景：磁盘请求队列
当前磁头位置：53
请求队列：98, 183, 37, 122, 14, 124, 65, 67

磁道范围：0-199
```

**1. FCFS（先来先服务）**

```
移动顺序：53 → 98 → 183 → 37 → 122 → 14 → 124 → 65 → 67

┌────────────────────────────────────────┐
│  0                                  199│
│  ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤  │
│     ↓  ↑                 ↓       ↑    │
│    14 37                65      98    │
│  53→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→98→│
│  →→→→→→→→→→→→→→→→→→→→→→→→→→→→→183   │
│  ←←←←←←←←←←←←←←←←←←←←←←←←←←←←←37     │
│  ... （来回移动）                       │
└────────────────────────────────────────┘

总移动：(98-53) + (183-98) + (183-37) + ... = 640磁道

✅ 公平
❌ 平均寻道时间长
```

**2. SSTF（最短寻道时间优先）**

```
移动顺序：53 → 65 → 67 → 37 → 14 → 98 → 122 → 124 → 183

每次选择距离当前位置最近的请求

总移动：(65-53) + (67-65) + (67-37) + (37-14) +
        (98-14) + (122-98) + (124-122) + (183-124)
      = 236磁道

✅ 平均寻道时间短
❌ 可能饥饿（中间磁道的请求优先，两端请求可能长时间等待）
```

**3. SCAN（电梯算法）**

```
移动顺序：53 → 65 → 67 → 98 → 122 → 124 → 183 → 199（端点）
                                           ↓
                  ← 37 ← 14 ← 0（端点）

┌────────────────────────────────────────┐
│  0                                  199│
│  ↓→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→↓  │
│  14  37  53  65 67   98 122124  183    │
│  ←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←  │
└────────────────────────────────────────┘

总移动：(199-53) + (199-14) = 331磁道

✅ 无饥饿
✅ 平均寻道时间较好
❌ 端点方向的请求等待时间长
```

**4. C-SCAN（循环扫描）**

```
移动顺序：53 → 65 → 67 → 98 → 122 → 124 → 183 → 199
                                           ↓
         （快速返回0） → 14 → 37

┌────────────────────────────────────────┐
│  0                                  199│
│  ↓→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→↓  │
│  14  37  53  65 67   98 122124  183    │
│  ↓→→→→→→                                │
└────────────────────────────────────────┘

🔑 特点：
- 单向扫描
- 到达端点后，快速返回起点（不处理请求）
- 等待时间更均匀

✅ 等待时间方差小
✅ 适合负载重的系统
```

**算法对比：**

```
算法     平均寻道时间   公平性   饥饿   适用场景
────────────────────────────────────────────
FCFS     最差          最好     无     负载轻
SSTF     最好          差       有     负载轻
SCAN     较好          较好     无     通用
C-SCAN   较好          最好     无     负载重
```

### 🎓 面试回答模板

```
【标准回答】

文件系统的核心是inode，它存储文件的元数据：
- 文件大小、权限、时间戳
- 数据块索引（直接块、间接块）
- 硬链接计数

但不包含文件名，文件名存储在目录项中。

【追问-硬链接vs软链接】

硬链接：
- 多个文件名指向同一个inode
- 删除一个不影响其他
- 不能跨文件系统，不能链接目录

软链接：
- 创建新的inode，内容是目标路径
- 目标删除后失效
- 可以跨文件系统，可以链接目录

【追问-inode如何支持大文件】

通过多级索引：
- 直接块：12个，最多48KB
- 一级间接：1024个块，最多4MB
- 二级间接：1024×1024个块，最多4GB
- 三级间接：最多4TB

小文件访问快（1次磁盘读），大文件也能支持。

【追问-磁盘调度】

常用SCAN算法（电梯算法）：
- 磁头沿一个方向移动，处理路径上的所有请求
- 到达端点后反向移动
- 避免饥饿，平均寻道时间较短
```

### ⚠️ 常见误区

❌ **错误1**：认为inode存储文件名
✅ **正确**：文件名存储在目录项中，inode只存储元数据

❌ **错误2**：认为删除文件立即释放空间
✅ **正确**：只有当硬链接计数和打开文件引用都为0时才释放

❌ **错误3**：认为软链接和硬链接一样
✅ **正确**：软链接是独立的文件，存储目标路径；硬链接共享inode

### 🌟 加分点

- 提到目录也是文件，内容是目录项列表
- 知道空洞文件的原理和应用
- 了解页缓存对文件I/O的优化
- 能说出C-SCAN相比SCAN的优势
- 知道临时文件的unlink技巧

---

## 同步与互斥

## 📌 互斥锁（Mutex）（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **临界区** | **原子操作** | **CAS** | **futex** | **自旋锁** | **睡眠锁** | **可重入锁** | **优先级反转**

### ✅ 核心概念

**临界区（Critical Section）：**
```
临界区：访问共享资源的代码段，同时只能有一个线程执行

问题场景：
线程1: count++;  // 读取count → 加1 → 写回count
线程2: count++;  // 同时操作

可能结果：
时刻1: 线程1读取count=0
时刻2: 线程2读取count=0
时刻3: 线程1写入count=1
时刻4: 线程2写入count=1
期望：count=2
实际：count=1（丢失一次更新）

🔑 解决：使用互斥锁保护临界区
```

### 💻 互斥锁实现原理（⭐⭐⭐⭐⭐ 底层必问）

**1. 原子操作基础：**

```cpp
// 🔑 x86架构的原子操作指令

// Test-and-Set（测试并设置）
bool test_and_set(bool* lock) {
    // 🔑 原子操作：读取旧值并设置新值
    asm volatile(
        "lock xchg %0, %1"  // lock前缀保证原子性
        : "+m" (*lock), "=r" (result)
        : "1" (true)
    );
    return result;
}

// Compare-and-Swap（比较并交换）
bool CAS(int* ptr, int expected, int new_value) {
    // 🔑 如果*ptr == expected，则设置*ptr = new_value
    // 返回true；否则返回false

    int old_value;
    asm volatile(
        "lock cmpxchg %2, %1"
        : "=a" (old_value), "+m" (*ptr)
        : "r" (new_value), "0" (expected)
    );
    return old_value == expected;
}

// 使用CAS实现自旋锁
class SpinLock {
    atomic<bool> locked{false};

public:
    void lock() {
        // 🔑 忙等待：不断尝试CAS直到成功
        while (locked.exchange(true, memory_order_acquire)) {
            // CPU空转，浪费CPU资源
            while (locked.load(memory_order_relaxed)) {
                // pause指令：减少CPU功耗
                _mm_pause();
            }
        }
    }

    void unlock() {
        locked.store(false, memory_order_release);
    }
};
```

**2. Mutex实现（结合自旋和睡眠）：**

```cpp
// 🔑 Linux pthread_mutex_t的简化实现

// 简化的互斥锁结构
typedef struct {
    int locked;           // 0=未锁，1=已锁
    pid_t owner;          // 持有锁的线程ID
    int waiters;          // 等待队列中的线程数
} pthread_mutex_t;

// 🔑 加锁实现（伪代码）
void pthread_mutex_lock(pthread_mutex_t* mutex) {
    while (1) {
        // 🔑 原子操作：test-and-set
        if (atomic_compare_and_swap(&mutex->locked, 0, 1) == 0) {
            // 成功获得锁
            mutex->owner = gettid();
            return;
        }

        // 🔑 未获得锁：进入睡眠等待
        futex_wait(&mutex->locked, 1);  // 系统调用
    }
}

void pthread_mutex_unlock(pthread_mutex_t* mutex) {
    mutex->owner = 0;
    atomic_store(&mutex->locked, 0);

    // 🔑 唤醒等待的线程
    if (mutex->waiters > 0) {
        futex_wake(&mutex->locked, 1);  // 系统调用
    }
}

// 🔑 futex（Fast Userspace Mutex）
// 在用户态尝试加锁（CAS），失败才进入内核态睡眠
// 优点：无竞争时完全在用户态，避免系统调用开销
```

**3. 自旋锁 vs 互斥锁：**

```
自旋锁（Spinlock）：
✅ 优点：
   - 无系统调用开销
   - 适合短时间持锁（几个CPU指令）
   - 适合多核系统

❌ 缺点：
   - 忙等待浪费CPU
   - 不适合长时间持锁
   - 单核系统性能差（需要等待时间片）

互斥锁（Mutex）：
✅ 优点：
   - 睡眠等待不浪费CPU
   - 适合长时间持锁
   - 适合单核系统

❌ 缺点：
   - 有系统调用开销（futex）
   - 上下文切换开销

🔑 选择策略：
临界区执行时间 < 2 * 上下文切换时间 → 自旋锁
临界区执行时间 > 2 * 上下文切换时间 → 互斥锁

典型值：
上下文切换：约1-2微秒
临界区：几条CPU指令（纳秒级） → 自旋锁
临界区：I/O操作（毫秒级） → 互斥锁
```

### 🔥 面试追问点

#### 1️⃣ 为什么需要原子操作？（⭐⭐⭐⭐⭐ 必问）

```cpp
// 问题：count++不是原子操作

// C++代码
int count = 0;
count++;

// 汇编代码（3条指令）
mov eax, [count]    // 1. 读取count到寄存器
add eax, 1          // 2. 寄存器+1
mov [count], eax    // 3. 写回内存

// 🔑 多线程执行时的问题：
时刻1: 线程1执行mov eax, [count]  (eax=0)
时刻2: 线程2执行mov eax, [count]  (eax=0)
时刻3: 线程1执行add eax, 1         (eax=1)
时刻4: 线程2执行add eax, 1         (eax=1)
时刻5: 线程1执行mov [count], eax   (count=1)
时刻6: 线程2执行mov [count], eax   (count=1)

结果：count=1（期望是2）

// ✅ 解决：使用原子操作
atomic<int> count{0};
count.fetch_add(1);  // 单条指令，硬件保证原子性

// x86汇编
lock add dword ptr [count], 1  // lock前缀保证原子性
```

#### 2️⃣ 什么是优先级反转？如何解决？（⭐⭐⭐⭐⭐ 核心）

```
优先级反转（Priority Inversion）：
高优先级线程被低优先级线程阻塞

场景：
1. 低优先级线程L获得锁
2. 高优先级线程H需要锁，阻塞
3. 中优先级线程M抢占L
4. H被M间接阻塞（H > M > L）

┌────────────────────────────────┐
│ 时间线：                         │
│ L: ───[获得锁]───被M抢占─────── │
│ M: ────────────[运行中]───────  │
│ H: ──────────[等待锁]──────────  │
│                ↑                │
│           🔑 H被M阻塞            │
└────────────────────────────────┘

🔑 解决方案1：优先级继承（Priority Inheritance）
L获得锁后，如果H等待，L临时提升到H的优先级
→ L以高优先级完成，释放锁
→ H获得锁

🔑 解决方案2：优先级天花板（Priority Ceiling）
锁有最高优先级属性
L获得锁时，立即提升到锁的最高优先级
→ M无法抢占L

代码示例：
pthread_mutex_t mutex;
pthread_mutexattr_t attr;
pthread_mutexattr_init(&attr);

// 设置优先级继承协议
pthread_mutexattr_setprotocol(&attr, PTHREAD_PRIO_INHERIT);

pthread_mutex_init(&mutex, &attr);
```

#### 3️⃣ 什么是可重入锁？（⭐⭐⭐⭐）

```cpp
// 递归锁（Recursive Mutex）：允许同一线程多次加锁

// ❌ 普通互斥锁：死锁
pthread_mutex_t mutex;

void funcA() {
    pthread_mutex_lock(&mutex);
    funcB();  // 调用funcB
    pthread_mutex_unlock(&mutex);
}

void funcB() {
    pthread_mutex_lock(&mutex);  // ❌ 死锁！同一线程重复加锁
    // ...
    pthread_mutex_unlock(&mutex);
}

// ✅ 可重入锁：允许递归
pthread_mutex_t rec_mutex;
pthread_mutexattr_t attr;

pthread_mutexattr_init(&attr);
pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);
pthread_mutex_init(&rec_mutex, &attr);

void funcA() {
    pthread_mutex_lock(&rec_mutex);
    funcB();  // ✅ 可以调用
    pthread_mutex_unlock(&rec_mutex);
}

void funcB() {
    pthread_mutex_lock(&rec_mutex);  // ✅ 成功（计数+1）
    // ...
    pthread_mutex_unlock(&rec_mutex);  // 计数-1
}

// 🔑 实现原理：
struct RecursiveMutex {
    pthread_mutex_t mutex;
    pthread_t owner;      // 持有者线程ID
    int count;            // 加锁计数
};

void recursive_lock(RecursiveMutex* m) {
    pthread_t self = pthread_self();

    if (m->owner == self) {
        // 🔑 已经是持有者：计数+1
        m->count++;
    } else {
        // 首次加锁
        pthread_mutex_lock(&m->mutex);
        m->owner = self;
        m->count = 1;
    }
}

void recursive_unlock(RecursiveMutex* m) {
    if (--m->count == 0) {
        m->owner = 0;
        pthread_mutex_unlock(&m->mutex);
    }
}
```

---

## 📌 条件变量（Condition Variable）（⭐⭐⭐⭐⭐ 必考）

### 🎯 得分关键词
> **wait** | **signal** | **broadcast** | **虚假唤醒** | **生产者-消费者** | **配合mutex** | **条件谓词**

### ✅ 核心概念

**条件变量的作用：**
```
问题：如何让线程等待某个条件满足？

❌ 错误方案：忙等待
while (!condition) {
    // 空转，浪费CPU
}

✅ 正确方案：条件变量
pthread_cond_wait(&cond, &mutex);
// 线程睡眠，不占用CPU
// 条件满足时被唤醒
```

**为什么需要配合mutex？**

```cpp
// 🔑 核心原因：避免竞态条件

// ❌ 错误示例：不用mutex
bool ready = false;
pthread_cond_t cond;

// 线程1：等待
if (!ready) {
    pthread_cond_wait(&cond);  // ❌ 竞态条件
}

// 线程2：通知
ready = true;
pthread_cond_signal(&cond);

// 问题：
时刻1: 线程1检查ready == false
时刻2: 线程2设置ready = true
时刻3: 线程2发送signal（无人等待）
时刻4: 线程1调用wait（永远等待）

// ✅ 正确：使用mutex保护
pthread_mutex_lock(&mutex);
while (!ready) {
    // 🔑 wait原子操作：
    // 1. 释放mutex
    // 2. 线程睡眠
    // 3. 被唤醒后重新获得mutex
    pthread_cond_wait(&cond, &mutex);
}
pthread_mutex_unlock(&mutex);
```

### 💻 生产者-消费者模式（⭐⭐⭐⭐⭐ 经典）

```cpp
#include <queue>
#include <pthread.h>

class BoundedQueue {
private:
    std::queue<int> queue;
    int capacity;
    pthread_mutex_t mutex;
    pthread_cond_t not_full;   // 队列不满
    pthread_cond_t not_empty;  // 队列不空

public:
    BoundedQueue(int cap) : capacity(cap) {
        pthread_mutex_init(&mutex, nullptr);
        pthread_cond_init(&not_full, nullptr);
        pthread_cond_init(&not_empty, nullptr);
    }

    // 🔑 生产者：放入数据
    void put(int data) {
        pthread_mutex_lock(&mutex);

        // 🔑 队列满时等待
        while (queue.size() >= capacity) {
            pthread_cond_wait(&not_full, &mutex);
        }

        queue.push(data);
        printf("Produced: %d, Size: %zu\n", data, queue.size());

        // 🔑 通知消费者：队列不空
        pthread_cond_signal(&not_empty);

        pthread_mutex_unlock(&mutex);
    }

    // 🔑 消费者：取出数据
    int get() {
        pthread_mutex_lock(&mutex);

        // 🔑 队列空时等待
        while (queue.empty()) {
            pthread_cond_wait(&not_empty, &mutex);
        }

        int data = queue.front();
        queue.pop();
        printf("Consumed: %d, Size: %zu\n", data, queue.size());

        // 🔑 通知生产者：队列不满
        pthread_cond_signal(&not_full);

        pthread_mutex_unlock(&mutex);
        return data;
    }
};

// 使用
void* producer(void* arg) {
    BoundedQueue* queue = (BoundedQueue*)arg;
    for (int i = 0; i < 10; ++i) {
        queue->put(i);
        sleep(1);
    }
    return nullptr;
}

void* consumer(void* arg) {
    BoundedQueue* queue = (BoundedQueue*)arg;
    for (int i = 0; i < 10; ++i) {
        int data = queue->get();
        sleep(2);
    }
    return nullptr;
}
```

### 🔥 面试追问点

#### 1️⃣ 为什么用while不用if检查条件？（⭐⭐⭐⭐⭐ 必问）

```cpp
// ❌ 错误：使用if
pthread_mutex_lock(&mutex);
if (queue.empty()) {
    pthread_cond_wait(&cond, &mutex);
}
int data = queue.front();  // ❌ 可能崩溃
pthread_mutex_unlock(&mutex);

// 问题：虚假唤醒（Spurious Wakeup）

场景1：信号丢失
1. 线程1等待（队列空）
2. 线程2放入数据，signal
3. 操作系统未立即唤醒线程1
4. 线程3取走数据（队列空）
5. 线程1被唤醒，直接访问queue.front() → 崩溃

场景2：多个线程等待
1. 线程1、线程2都等待（队列空）
2. 线程3放入1个数据，broadcast
3. 线程1被唤醒，取走数据
4. 线程2被唤醒，queue.empty() → 崩溃

场景3：操作系统虚假唤醒
Linux允许pthread_cond_wait无理由返回
→ 必须重新检查条件

// ✅ 正确：使用while
pthread_mutex_lock(&mutex);
while (queue.empty()) {  // 🔑 循环检查
    pthread_cond_wait(&cond, &mutex);
}
int data = queue.front();  // ✅ 安全
pthread_mutex_unlock(&mutex);
```

#### 2️⃣ signal vs broadcast的区别？（⭐⭐⭐⭐）

```cpp
// signal：唤醒一个等待线程
pthread_cond_signal(&cond);

// broadcast：唤醒所有等待线程
pthread_cond_broadcast(&cond);

// 🔑 使用场景：

// 1. 单一条件 → signal
// 生产者-消费者：
put() {
    queue.push(data);
    pthread_cond_signal(&not_empty);  // 只需唤醒1个消费者
}

// 2. 多个不同条件 → broadcast
// 读者-写者：
writer_unlock() {
    writing = false;
    pthread_cond_broadcast(&cond);  // 唤醒所有读者和写者
    // 让他们重新竞争
}

// 3. 条件复杂 → broadcast
// 例如：等待count达到阈值
if (count >= threshold) {
    pthread_cond_broadcast(&cond);  // 所有等待线程都检查
}

// 性能对比：
signal：O(1) 唤醒开销
broadcast：O(N) 唤醒开销（N个等待线程）

// 🔑 选择原则：
能用signal就用signal（性能更好）
必要时才用broadcast（避免饥饿）
```

---

## 📌 读写锁（Read-Write Lock）（⭐⭐⭐⭐）

### 🎯 得分关键词
> **共享锁** | **排他锁** | **读者优先** | **写者优先** | **公平策略** | **读写比例** | **写者饥饿**

### ✅ 核心概念

**读写锁的作用：**
```
问题：数据读多写少，mutex效率低

场景：配置文件
- 读取：1000次/秒
- 更新：1次/秒

mutex：所有操作都互斥（浪费）
读写锁：
- 多个读者可以同时读
- 写者独占访问
```

**三种策略：**

```
1. 读者优先（Reader-Preferring）
   只要有读者，新来的读者可以立即获得锁
   ❌ 问题：写者可能饥饿

2. 写者优先（Writer-Preferring）
   有写者等待时，不再允许新读者
   ❌ 问题：读者可能饥饿

3. 公平策略（Fair）
   按FIFO顺序分配锁
   ✅ 无饥饿，但实现复杂
```

### 💻 读写锁实现（⭐⭐⭐⭐）

```cpp
// 🔑 简化的读写锁结构
typedef struct {
    pthread_mutex_t mutex;        // 保护锁状态
    pthread_cond_t read_cond;     // 读者等待队列
    pthread_cond_t write_cond;    // 写者等待队列

    int readers;                  // 当前读者数量
    int writers;                  // 当前写者数量（0或1）
    int waiting_writers;          // 等待的写者数量

    int policy;                   // 策略：读者优先/写者优先/公平
} pthread_rwlock_t;

// 🔑 读者加锁（写者优先策略）
void pthread_rwlock_rdlock(pthread_rwlock_t* rwlock) {
    pthread_mutex_lock(&rwlock->mutex);

    // 🔑 有写者或有写者等待时，读者等待
    while (rwlock->writers > 0 || rwlock->waiting_writers > 0) {
        pthread_cond_wait(&rwlock->read_cond, &rwlock->mutex);
    }

    rwlock->readers++;

    pthread_mutex_unlock(&rwlock->mutex);
}

void pthread_rwlock_rdunlock(pthread_rwlock_t* rwlock) {
    pthread_mutex_lock(&rwlock->mutex);

    rwlock->readers--;

    // 🔑 最后一个读者离开，唤醒写者
    if (rwlock->readers == 0) {
        pthread_cond_signal(&rwlock->write_cond);
    }

    pthread_mutex_unlock(&rwlock->mutex);
}

// 🔑 写者加锁
void pthread_rwlock_wrlock(pthread_rwlock_t* rwlock) {
    pthread_mutex_lock(&rwlock->mutex);

    rwlock->waiting_writers++;

    // 🔑 有读者或有写者时，等待
    while (rwlock->readers > 0 || rwlock->writers > 0) {
        pthread_cond_wait(&rwlock->write_cond, &rwlock->mutex);
    }

    rwlock->waiting_writers--;
    rwlock->writers = 1;

    pthread_mutex_unlock(&rwlock->mutex);
}

void pthread_rwlock_wrunlock(pthread_rwlock_t* rwlock) {
    pthread_mutex_lock(&rwlock->mutex);

    rwlock->writers = 0;

    // 🔑 优先唤醒等待的写者
    if (rwlock->waiting_writers > 0) {
        pthread_cond_signal(&rwlock->write_cond);
    } else {
        // 没有写者，唤醒所有读者
        pthread_cond_broadcast(&rwlock->read_cond);
    }

    pthread_mutex_unlock(&rwlock->mutex);
}
```

### 🔥 面试追问点

#### 1️⃣ 读写锁适用场景？性能对比？（⭐⭐⭐⭐⭐ 重要）

```cpp
// 🔑 性能测试

// 场景：10个线程，读写比例9:1

// 测试1：使用mutex
pthread_mutex_t mutex;

void* reader(void*) {
    for (int i = 0; i < 10000; ++i) {
        pthread_mutex_lock(&mutex);
        // 读取数据
        pthread_mutex_unlock(&mutex);
    }
}

void* writer(void*) {
    for (int i = 0; i < 1000; ++i) {
        pthread_mutex_lock(&mutex);
        // 写入数据
        pthread_mutex_unlock(&mutex);
    }
}
// 耗时：约500ms

// 测试2：使用读写锁
pthread_rwlock_t rwlock;

void* reader(void*) {
    for (int i = 0; i < 10000; ++i) {
        pthread_rwlock_rdlock(&rwlock);
        // 读取数据
        pthread_rwlock_unlock(&rwlock);
    }
}

void* writer(void*) {
    for (int i = 0; i < 1000; ++i) {
        pthread_rwlock_wrlock(&rwlock);
        // 写入数据
        pthread_rwlock_unlock(&rwlock);
    }
}
// 耗时：约100ms（提升5倍）

// 🔑 性能分析：
读写比例    Mutex    RWLock    提升
10:0 (只读)   100ms    20ms    5倍
9:1          500ms   100ms    5倍
5:5         1000ms   800ms   1.25倍
1:9         1500ms  1400ms   1.07倍

// 🔑 适用场景：
✅ 读多写少（读写比 > 5:1）
✅ 临界区较大（值得额外开销）
❌ 写多读少（不如mutex）
❌ 临界区很小（开销大于收益）
```

#### 2️⃣ 如何防止写者饥饿？（⭐⭐⭐⭐）

```cpp
// 问题：读者优先策略下，写者可能永远等待

// 场景：
时刻1: 读者1获得锁
时刻2: 写者1等待
时刻3: 读者2到达，立即获得锁（读者优先）
时刻4: 读者3到达，立即获得锁
...
写者1永远等待

// 🔑 解决方案1：写者优先
// 有写者等待时，阻止新读者

void pthread_rwlock_rdlock(pthread_rwlock_t* rwlock) {
    pthread_mutex_lock(&rwlock->mutex);

    // 🔑 有写者等待时，读者也要等待
    while (rwlock->writers > 0 || rwlock->waiting_writers > 0) {
        pthread_cond_wait(&rwlock->read_cond, &rwlock->mutex);
    }

    rwlock->readers++;
    pthread_mutex_unlock(&rwlock->mutex);
}

// 🔑 解决方案2：公平策略（FIFO队列）
struct FairRWLock {
    queue<pair<bool, pthread_cond_t*>> wait_queue;  // <is_writer, cond>

    void rdlock() {
        pthread_mutex_lock(&mutex);

        if (writers == 0 && wait_queue.empty()) {
            // 无写者且无等待，直接获得
            readers++;
        } else {
            // 进入FIFO队列等待
            pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
            wait_queue.push({false, &cond});

            pthread_cond_wait(&cond, &mutex);
            readers++;
        }

        pthread_mutex_unlock(&mutex);
    }
};

// 🔑 解决方案3：混合策略
// 读者数量达到阈值后，强制让写者执行
if (rwlock->readers >= MAX_READERS && rwlock->waiting_writers > 0) {
    // 不再允许新读者
}
```

### 🎓 面试回答模板

```
【标准回答】

同步互斥主要有三种机制：

1. 互斥锁（Mutex）
   - 保护临界区，同时只有一个线程访问
   - 底层使用原子操作（CAS）+ futex
   - 适用场景：保护共享数据

2. 条件变量（Condition Variable）
   - 让线程等待条件满足
   - 必须配合mutex使用（避免竞态条件）
   - 适用场景：生产者-消费者模式

3. 读写锁（RWLock）
   - 读者共享，写者独占
   - 适用读多写少场景
   - 性能优于mutex（读写比>5:1）

【追问-原子操作】
原子操作是不可分割的操作，硬件保证执行过程不被打断。
常见的有CAS（比较并交换）、test-and-set。
用于实现锁的底层机制。

【追问-条件变量为何用while】
因为存在虚假唤醒：
1. 信号丢失
2. 多个线程竞争
3. 操作系统虚假唤醒
必须循环检查条件是否真正满足。

【追问-读写锁性能】
读写比10:1时，读写锁比mutex快约5倍。
但写多读少时，不如mutex（额外开销）。
```

### ⚠️ 常见误区

❌ **错误1**：认为count++是原子操作
✅ **正确**：count++是3条汇编指令，需要用atomic或mutex保护

❌ **错误2**：条件变量用if检查
✅ **正确**：必须用while循环检查（防止虚假唤醒）

❌ **错误3**：读写锁一定比mutex快
✅ **正确**：只有读多写少时才快，写多时更慢

### 🌟 加分点

- 说出CAS的原理和汇编实现
- 知道futex是什么（Fast Userspace Mutex）
- 了解优先级反转和解决方案
- 能解释虚假唤醒的三种场景
- 知道读写锁的三种策略差异

---
